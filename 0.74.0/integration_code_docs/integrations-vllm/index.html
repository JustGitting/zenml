
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
        <link rel="canonical" href="https://sdkdocs.zenml.io/0.74.0/integration_code_docs/integrations-vllm/">
      
      <link rel="icon" href="../../_assets/favicon.png">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-8.5.10">
    
    
      
        <title>Vllm - ZenML API Reference</title>
      
    
    
      <link rel="stylesheet" href="../../assets/stylesheets/main.975780f9.min.css">
      
        
        <link rel="stylesheet" href="../../assets/stylesheets/palette.2505c338.min.css">
        
      
      

    
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../../assets/_mkdocstrings.css">
    
    <script>__md_scope=new URL("../..",location),__md_hash=e=>[...e].reduce((e,_)=>(e<<5)-e+_.charCodeAt(0),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    

<script>
  !function(){var analytics=window.analytics=window.analytics||[];if(!analytics.initialize)if(analytics.invoked)window.console&&console.error&&console.error("Segment snippet included twice.");else{analytics.invoked=!0;analytics.methods=["trackSubmit","trackClick","trackLink","trackForm","pageview","identify","reset","group","track","ready","alias","debug","page","once","off","on","addSourceMiddleware","addIntegrationMiddleware","setAnonymousId","addDestinationMiddleware"];analytics.factory=function(e){return function(){var t=Array.prototype.slice.call(arguments);t.unshift(e);analytics.push(t);return analytics}};for(var e=0;e<analytics.methods.length;e++){var key=analytics.methods[e];analytics[key]=analytics.factory(key)}analytics.load=function(key,e){var t=document.createElement("script");t.type="text/javascript";t.async=!0;t.src="https://cdn.segment.com/analytics.js/v1/" + key + "/analytics.min.js";var n=document.getElementsByTagName("script")[0];n.parentNode.insertBefore(t,n);analytics._loadOptions=e};analytics._writeKey="CaE5VaNjhyaUt48qXK4rLwwKJ0PdAOFM";;analytics.SNIPPET_VERSION="4.15.3";
  analytics.load("CaE5VaNjhyaUt48qXK4rLwwKJ0PdAOFM");
  analytics.page();
  }}();
</script>
<script defer data-domain="apidocs.zenml.io" src="https://plausible.io/js/plausible.js"></script>


  </head>
  
  
    
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="None" data-md-color-accent="None">
  
    
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#vllm" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
      <div data-md-component="outdated" hidden>
        
      </div>
    
    
      

<header class="md-header" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../.." title="ZenML API Reference" class="md-header__button md-logo" aria-label="ZenML API Reference" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54Z"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2Z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            ZenML API Reference
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Vllm
            
          </span>
        </div>
      </div>
    </div>
    
    
    
      <label class="md-header__button md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41Z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
      <div class="md-header__source">
        <a href="https://github.com/zenml-io/zenml" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.2.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"/></svg>
  </div>
  <div class="md-source__repository">
    GitHub
  </div>
</a>
      </div>
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../.." title="ZenML API Reference" class="md-nav__button md-logo" aria-label="ZenML API Reference" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54Z"/></svg>

    </a>
    ZenML API Reference
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/zenml-io/zenml" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.2.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"/></svg>
  </div>
  <div class="md-source__repository">
    GitHub
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../.." class="md-nav__link">
        ZenML
      </a>
    </li>
  

    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../../cli/" class="md-nav__link">
        CLI docs
      </a>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_3" type="checkbox" id="__nav_3" >
      
      
      
      
        <label class="md-nav__link" for="__nav_3">
          Core code docs
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Core code docs" data-md-level="1">
        <label class="md-nav__title" for="__nav_3">
          <span class="md-nav__icon md-icon"></span>
          Core code docs
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../core_code_docs/core-actions/" class="md-nav__link">
        Actions
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../core_code_docs/core-alerter/" class="md-nav__link">
        Alerter
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../core_code_docs/core-analytics/" class="md-nav__link">
        Analytics
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../core_code_docs/core-annotators/" class="md-nav__link">
        Annotators
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../core_code_docs/core-artifact_stores/" class="md-nav__link">
        Artifact Stores
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../core_code_docs/core-artifacts/" class="md-nav__link">
        Artifacts
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../core_code_docs/core-client/" class="md-nav__link">
        Client
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../core_code_docs/core-client_lazy_loader/" class="md-nav__link">
        Client Lazy Loader
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../core_code_docs/core-code_repositories/" class="md-nav__link">
        Code Repositories
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../core_code_docs/core-config/" class="md-nav__link">
        Config
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../core_code_docs/core-console/" class="md-nav__link">
        Console
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../core_code_docs/core-constants/" class="md-nav__link">
        Constants
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../core_code_docs/core-container_registries/" class="md-nav__link">
        Container Registries
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../core_code_docs/core-data_validators/" class="md-nav__link">
        Data Validators
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../core_code_docs/core-entrypoints/" class="md-nav__link">
        Entrypoints
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../core_code_docs/core-enums/" class="md-nav__link">
        Enums
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../core_code_docs/core-environment/" class="md-nav__link">
        Environment
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../core_code_docs/core-event_hub/" class="md-nav__link">
        Event Hub
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../core_code_docs/core-event_sources/" class="md-nav__link">
        Event Sources
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../core_code_docs/core-exceptions/" class="md-nav__link">
        Exceptions
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../core_code_docs/core-experiment_trackers/" class="md-nav__link">
        Experiment Trackers
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../core_code_docs/core-feature_stores/" class="md-nav__link">
        Feature Stores
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../core_code_docs/core-hooks/" class="md-nav__link">
        Hooks
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../core_code_docs/core-image_builders/" class="md-nav__link">
        Image Builders
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../core_code_docs/core-io/" class="md-nav__link">
        Io
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../core_code_docs/core-logger/" class="md-nav__link">
        Logger
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../core_code_docs/core-logging/" class="md-nav__link">
        Logging
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../core_code_docs/core-login/" class="md-nav__link">
        Login
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../core_code_docs/core-materializers/" class="md-nav__link">
        Materializers
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../core_code_docs/core-metadata/" class="md-nav__link">
        Metadata
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../core_code_docs/core-model/" class="md-nav__link">
        Model
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../core_code_docs/core-model_deployers/" class="md-nav__link">
        Model Deployers
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../core_code_docs/core-model_registries/" class="md-nav__link">
        Model Registries
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../core_code_docs/core-models/" class="md-nav__link">
        Models
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../core_code_docs/core-orchestrators/" class="md-nav__link">
        Orchestrators
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../core_code_docs/core-pipelines/" class="md-nav__link">
        Pipelines
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../core_code_docs/core-plugins/" class="md-nav__link">
        Plugins
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../core_code_docs/core-secret/" class="md-nav__link">
        Secret
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../core_code_docs/core-service_connectors/" class="md-nav__link">
        Service Connectors
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../core_code_docs/core-services/" class="md-nav__link">
        Services
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../core_code_docs/core-stack/" class="md-nav__link">
        Stack
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../core_code_docs/core-stack_deployments/" class="md-nav__link">
        Stack Deployments
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../core_code_docs/core-step_operators/" class="md-nav__link">
        Step Operators
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../core_code_docs/core-steps/" class="md-nav__link">
        Steps
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../core_code_docs/core-types/" class="md-nav__link">
        Types
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../core_code_docs/core-utils/" class="md-nav__link">
        Utils
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../core_code_docs/core-zen_server/" class="md-nav__link">
        Zen Server
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../core_code_docs/core-zen_stores/" class="md-nav__link">
        Zen Stores
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
    
  
  
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_4" type="checkbox" id="__nav_4" checked>
      
      
      
      
        <label class="md-nav__link" for="__nav_4">
          Integration code docs
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Integration code docs" data-md-level="1">
        <label class="md-nav__title" for="__nav_4">
          <span class="md-nav__icon md-icon"></span>
          Integration code docs
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../integrations-airflow/" class="md-nav__link">
        Airflow
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../integrations-argilla/" class="md-nav__link">
        Argilla
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../integrations-aws/" class="md-nav__link">
        Aws
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../integrations-azure/" class="md-nav__link">
        Azure
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../integrations-bentoml/" class="md-nav__link">
        Bentoml
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../integrations-bitbucket/" class="md-nav__link">
        Bitbucket
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../integrations-comet/" class="md-nav__link">
        Comet
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../integrations-constants/" class="md-nav__link">
        Constants
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../integrations-databricks/" class="md-nav__link">
        Databricks
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../integrations-deepchecks/" class="md-nav__link">
        Deepchecks
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../integrations-discord/" class="md-nav__link">
        Discord
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../integrations-evidently/" class="md-nav__link">
        Evidently
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../integrations-facets/" class="md-nav__link">
        Facets
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../integrations-feast/" class="md-nav__link">
        Feast
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../integrations-gcp/" class="md-nav__link">
        Gcp
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../integrations-github/" class="md-nav__link">
        Github
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../integrations-gitlab/" class="md-nav__link">
        Gitlab
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../integrations-great_expectations/" class="md-nav__link">
        Great Expectations
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../integrations-huggingface/" class="md-nav__link">
        Huggingface
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../integrations-hyperai/" class="md-nav__link">
        Hyperai
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../integrations-integration/" class="md-nav__link">
        Integration
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../integrations-kaniko/" class="md-nav__link">
        Kaniko
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../integrations-kubeflow/" class="md-nav__link">
        Kubeflow
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../integrations-kubernetes/" class="md-nav__link">
        Kubernetes
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../integrations-label_studio/" class="md-nav__link">
        Label Studio
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../integrations-langchain/" class="md-nav__link">
        Langchain
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../integrations-lightgbm/" class="md-nav__link">
        Lightgbm
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../integrations-lightning/" class="md-nav__link">
        Lightning
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../integrations-llama_index/" class="md-nav__link">
        Llama Index
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../integrations-mlflow/" class="md-nav__link">
        Mlflow
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../integrations-modal/" class="md-nav__link">
        Modal
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../integrations-neptune/" class="md-nav__link">
        Neptune
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../integrations-neural_prophet/" class="md-nav__link">
        Neural Prophet
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../integrations-numpy/" class="md-nav__link">
        Numpy
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../integrations-openai/" class="md-nav__link">
        Openai
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../integrations-pandas/" class="md-nav__link">
        Pandas
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../integrations-pigeon/" class="md-nav__link">
        Pigeon
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../integrations-pillow/" class="md-nav__link">
        Pillow
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../integrations-polars/" class="md-nav__link">
        Polars
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../integrations-prodigy/" class="md-nav__link">
        Prodigy
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../integrations-pycaret/" class="md-nav__link">
        Pycaret
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../integrations-pytorch/" class="md-nav__link">
        Pytorch
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../integrations-pytorch_lightning/" class="md-nav__link">
        Pytorch Lightning
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../integrations-registry/" class="md-nav__link">
        Registry
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../integrations-s3/" class="md-nav__link">
        S3
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../integrations-scipy/" class="md-nav__link">
        Scipy
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../integrations-seldon/" class="md-nav__link">
        Seldon
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../integrations-sklearn/" class="md-nav__link">
        Sklearn
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../integrations-skypilot/" class="md-nav__link">
        Skypilot
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../integrations-skypilot_aws/" class="md-nav__link">
        Skypilot Aws
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../integrations-skypilot_azure/" class="md-nav__link">
        Skypilot Azure
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../integrations-skypilot_gcp/" class="md-nav__link">
        Skypilot Gcp
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../integrations-skypilot_kubernetes/" class="md-nav__link">
        Skypilot Kubernetes
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../integrations-skypilot_lambda/" class="md-nav__link">
        Skypilot Lambda
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../integrations-slack/" class="md-nav__link">
        Slack
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../integrations-spark/" class="md-nav__link">
        Spark
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../integrations-tekton/" class="md-nav__link">
        Tekton
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../integrations-tensorboard/" class="md-nav__link">
        Tensorboard
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../integrations-tensorflow/" class="md-nav__link">
        Tensorflow
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../integrations-utils/" class="md-nav__link">
        Utils
      </a>
    </li>
  

            
          
            
              
  
  
    
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" data-md-toggle="toc" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          Vllm
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        Vllm
      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#zenml.integrations.vllm" class="md-nav__link">
    vllm
  </a>
  
    <nav class="md-nav" aria-label="vllm">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#zenml.integrations.vllm.VLLMIntegration" class="md-nav__link">
    VLLMIntegration
  </a>
  
    <nav class="md-nav" aria-label="VLLMIntegration">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#zenml.integrations.vllm.VLLMIntegration.activate" class="md-nav__link">
    activate()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#zenml.integrations.vllm.VLLMIntegration.flavors" class="md-nav__link">
    flavors()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#zenml.integrations.vllm.flavors" class="md-nav__link">
    flavors
  </a>
  
    <nav class="md-nav" aria-label="flavors">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#zenml.integrations.vllm.flavors.vllm_model_deployer_flavor" class="md-nav__link">
    vllm_model_deployer_flavor
  </a>
  
    <nav class="md-nav" aria-label="vllm_model_deployer_flavor">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#zenml.integrations.vllm.flavors.vllm_model_deployer_flavor.VLLMModelDeployerConfig" class="md-nav__link">
    VLLMModelDeployerConfig
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#zenml.integrations.vllm.flavors.vllm_model_deployer_flavor.VLLMModelDeployerFlavor" class="md-nav__link">
    VLLMModelDeployerFlavor
  </a>
  
    <nav class="md-nav" aria-label="VLLMModelDeployerFlavor">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#zenml.integrations.vllm.flavors.vllm_model_deployer_flavor.VLLMModelDeployerFlavor.config_class" class="md-nav__link">
    config_class
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#zenml.integrations.vllm.flavors.vllm_model_deployer_flavor.VLLMModelDeployerFlavor.docs_url" class="md-nav__link">
    docs_url
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#zenml.integrations.vllm.flavors.vllm_model_deployer_flavor.VLLMModelDeployerFlavor.implementation_class" class="md-nav__link">
    implementation_class
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#zenml.integrations.vllm.flavors.vllm_model_deployer_flavor.VLLMModelDeployerFlavor.logo_url" class="md-nav__link">
    logo_url
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#zenml.integrations.vllm.flavors.vllm_model_deployer_flavor.VLLMModelDeployerFlavor.name" class="md-nav__link">
    name
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#zenml.integrations.vllm.flavors.vllm_model_deployer_flavor.VLLMModelDeployerFlavor.sdk_docs_url" class="md-nav__link">
    sdk_docs_url
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#zenml.integrations.vllm.model_deployers" class="md-nav__link">
    model_deployers
  </a>
  
    <nav class="md-nav" aria-label="model_deployers">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#zenml.integrations.vllm.model_deployers.vllm_model_deployer" class="md-nav__link">
    vllm_model_deployer
  </a>
  
    <nav class="md-nav" aria-label="vllm_model_deployer">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#zenml.integrations.vllm.model_deployers.vllm_model_deployer.VLLMModelDeployer" class="md-nav__link">
    VLLMModelDeployer
  </a>
  
    <nav class="md-nav" aria-label="VLLMModelDeployer">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#zenml.integrations.vllm.model_deployers.vllm_model_deployer.VLLMModelDeployer.config" class="md-nav__link">
    config
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#zenml.integrations.vllm.model_deployers.vllm_model_deployer.VLLMModelDeployer.local_path" class="md-nav__link">
    local_path
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#zenml.integrations.vllm.model_deployers.vllm_model_deployer.VLLMModelDeployer.FLAVOR" class="md-nav__link">
    FLAVOR
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#zenml.integrations.vllm.model_deployers.vllm_model_deployer.VLLMModelDeployer.get_model_server_info" class="md-nav__link">
    get_model_server_info()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#zenml.integrations.vllm.model_deployers.vllm_model_deployer.VLLMModelDeployer.get_service_path" class="md-nav__link">
    get_service_path()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#zenml.integrations.vllm.model_deployers.vllm_model_deployer.VLLMModelDeployer.perform_delete_model" class="md-nav__link">
    perform_delete_model()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#zenml.integrations.vllm.model_deployers.vllm_model_deployer.VLLMModelDeployer.perform_deploy_model" class="md-nav__link">
    perform_deploy_model()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#zenml.integrations.vllm.model_deployers.vllm_model_deployer.VLLMModelDeployer.perform_start_model" class="md-nav__link">
    perform_start_model()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#zenml.integrations.vllm.model_deployers.vllm_model_deployer.VLLMModelDeployer.perform_stop_model" class="md-nav__link">
    perform_stop_model()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#zenml.integrations.vllm.services" class="md-nav__link">
    services
  </a>
  
    <nav class="md-nav" aria-label="services">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#zenml.integrations.vllm.services.vllm_deployment" class="md-nav__link">
    vllm_deployment
  </a>
  
    <nav class="md-nav" aria-label="vllm_deployment">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#zenml.integrations.vllm.services.vllm_deployment.VLLMDeploymentEndpoint" class="md-nav__link">
    VLLMDeploymentEndpoint
  </a>
  
    <nav class="md-nav" aria-label="VLLMDeploymentEndpoint">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#zenml.integrations.vllm.services.vllm_deployment.VLLMDeploymentEndpoint.prediction_url" class="md-nav__link">
    prediction_url
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#zenml.integrations.vllm.services.vllm_deployment.VLLMDeploymentEndpointConfig" class="md-nav__link">
    VLLMDeploymentEndpointConfig
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#zenml.integrations.vllm.services.vllm_deployment.VLLMDeploymentService" class="md-nav__link">
    VLLMDeploymentService
  </a>
  
    <nav class="md-nav" aria-label="VLLMDeploymentService">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#zenml.integrations.vllm.services.vllm_deployment.VLLMDeploymentService.prediction_url" class="md-nav__link">
    prediction_url
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#zenml.integrations.vllm.services.vllm_deployment.VLLMDeploymentService.__init__" class="md-nav__link">
    __init__()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#zenml.integrations.vllm.services.vllm_deployment.VLLMDeploymentService.predict" class="md-nav__link">
    predict()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#zenml.integrations.vllm.services.vllm_deployment.VLLMDeploymentService.run" class="md-nav__link">
    run()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#zenml.integrations.vllm.services.vllm_deployment.VLLMServiceConfig" class="md-nav__link">
    VLLMServiceConfig
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../integrations-wandb/" class="md-nav__link">
        Wandb
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../integrations-whylogs/" class="md-nav__link">
        Whylogs
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../integrations-xgboost/" class="md-nav__link">
        Xgboost
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#zenml.integrations.vllm" class="md-nav__link">
    vllm
  </a>
  
    <nav class="md-nav" aria-label="vllm">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#zenml.integrations.vllm.VLLMIntegration" class="md-nav__link">
    VLLMIntegration
  </a>
  
    <nav class="md-nav" aria-label="VLLMIntegration">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#zenml.integrations.vllm.VLLMIntegration.activate" class="md-nav__link">
    activate()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#zenml.integrations.vllm.VLLMIntegration.flavors" class="md-nav__link">
    flavors()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#zenml.integrations.vllm.flavors" class="md-nav__link">
    flavors
  </a>
  
    <nav class="md-nav" aria-label="flavors">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#zenml.integrations.vllm.flavors.vllm_model_deployer_flavor" class="md-nav__link">
    vllm_model_deployer_flavor
  </a>
  
    <nav class="md-nav" aria-label="vllm_model_deployer_flavor">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#zenml.integrations.vllm.flavors.vllm_model_deployer_flavor.VLLMModelDeployerConfig" class="md-nav__link">
    VLLMModelDeployerConfig
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#zenml.integrations.vllm.flavors.vllm_model_deployer_flavor.VLLMModelDeployerFlavor" class="md-nav__link">
    VLLMModelDeployerFlavor
  </a>
  
    <nav class="md-nav" aria-label="VLLMModelDeployerFlavor">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#zenml.integrations.vllm.flavors.vllm_model_deployer_flavor.VLLMModelDeployerFlavor.config_class" class="md-nav__link">
    config_class
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#zenml.integrations.vllm.flavors.vllm_model_deployer_flavor.VLLMModelDeployerFlavor.docs_url" class="md-nav__link">
    docs_url
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#zenml.integrations.vllm.flavors.vllm_model_deployer_flavor.VLLMModelDeployerFlavor.implementation_class" class="md-nav__link">
    implementation_class
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#zenml.integrations.vllm.flavors.vllm_model_deployer_flavor.VLLMModelDeployerFlavor.logo_url" class="md-nav__link">
    logo_url
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#zenml.integrations.vllm.flavors.vllm_model_deployer_flavor.VLLMModelDeployerFlavor.name" class="md-nav__link">
    name
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#zenml.integrations.vllm.flavors.vllm_model_deployer_flavor.VLLMModelDeployerFlavor.sdk_docs_url" class="md-nav__link">
    sdk_docs_url
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#zenml.integrations.vllm.model_deployers" class="md-nav__link">
    model_deployers
  </a>
  
    <nav class="md-nav" aria-label="model_deployers">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#zenml.integrations.vllm.model_deployers.vllm_model_deployer" class="md-nav__link">
    vllm_model_deployer
  </a>
  
    <nav class="md-nav" aria-label="vllm_model_deployer">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#zenml.integrations.vllm.model_deployers.vllm_model_deployer.VLLMModelDeployer" class="md-nav__link">
    VLLMModelDeployer
  </a>
  
    <nav class="md-nav" aria-label="VLLMModelDeployer">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#zenml.integrations.vllm.model_deployers.vllm_model_deployer.VLLMModelDeployer.config" class="md-nav__link">
    config
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#zenml.integrations.vllm.model_deployers.vllm_model_deployer.VLLMModelDeployer.local_path" class="md-nav__link">
    local_path
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#zenml.integrations.vllm.model_deployers.vllm_model_deployer.VLLMModelDeployer.FLAVOR" class="md-nav__link">
    FLAVOR
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#zenml.integrations.vllm.model_deployers.vllm_model_deployer.VLLMModelDeployer.get_model_server_info" class="md-nav__link">
    get_model_server_info()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#zenml.integrations.vllm.model_deployers.vllm_model_deployer.VLLMModelDeployer.get_service_path" class="md-nav__link">
    get_service_path()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#zenml.integrations.vllm.model_deployers.vllm_model_deployer.VLLMModelDeployer.perform_delete_model" class="md-nav__link">
    perform_delete_model()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#zenml.integrations.vllm.model_deployers.vllm_model_deployer.VLLMModelDeployer.perform_deploy_model" class="md-nav__link">
    perform_deploy_model()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#zenml.integrations.vllm.model_deployers.vllm_model_deployer.VLLMModelDeployer.perform_start_model" class="md-nav__link">
    perform_start_model()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#zenml.integrations.vllm.model_deployers.vllm_model_deployer.VLLMModelDeployer.perform_stop_model" class="md-nav__link">
    perform_stop_model()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#zenml.integrations.vllm.services" class="md-nav__link">
    services
  </a>
  
    <nav class="md-nav" aria-label="services">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#zenml.integrations.vllm.services.vllm_deployment" class="md-nav__link">
    vllm_deployment
  </a>
  
    <nav class="md-nav" aria-label="vllm_deployment">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#zenml.integrations.vllm.services.vllm_deployment.VLLMDeploymentEndpoint" class="md-nav__link">
    VLLMDeploymentEndpoint
  </a>
  
    <nav class="md-nav" aria-label="VLLMDeploymentEndpoint">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#zenml.integrations.vllm.services.vllm_deployment.VLLMDeploymentEndpoint.prediction_url" class="md-nav__link">
    prediction_url
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#zenml.integrations.vllm.services.vllm_deployment.VLLMDeploymentEndpointConfig" class="md-nav__link">
    VLLMDeploymentEndpointConfig
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#zenml.integrations.vllm.services.vllm_deployment.VLLMDeploymentService" class="md-nav__link">
    VLLMDeploymentService
  </a>
  
    <nav class="md-nav" aria-label="VLLMDeploymentService">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#zenml.integrations.vllm.services.vllm_deployment.VLLMDeploymentService.prediction_url" class="md-nav__link">
    prediction_url
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#zenml.integrations.vllm.services.vllm_deployment.VLLMDeploymentService.__init__" class="md-nav__link">
    __init__()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#zenml.integrations.vllm.services.vllm_deployment.VLLMDeploymentService.predict" class="md-nav__link">
    predict()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#zenml.integrations.vllm.services.vllm_deployment.VLLMDeploymentService.run" class="md-nav__link">
    run()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#zenml.integrations.vllm.services.vllm_deployment.VLLMServiceConfig" class="md-nav__link">
    VLLMServiceConfig
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  

  <a href="https://github.com/zenml-io/zenml/docs/integration_code_docs/integrations-vllm.md" title="Edit this page" class="md-content__button md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20.71 7.04c.39-.39.39-1.04 0-1.41l-2.34-2.34c-.37-.39-1.02-.39-1.41 0l-1.84 1.83 3.75 3.75M3 17.25V21h3.75L17.81 9.93l-3.75-3.75L3 17.25Z"/></svg>
  </a>


<h1 id="vllm">Vllm</h1>


  <div class="doc doc-object doc-module">



<h2 id="zenml.integrations.vllm" class="doc doc-heading">
        <code>zenml.integrations.vllm</code>


  <span class="doc doc-properties">
      <small class="doc doc-property doc-property-special"><code>special</code></small>
  </span>

</h2>

    <div class="doc doc-contents first">

      <p>Initialization for the ZenML vLLM integration.</p>



  <div class="doc doc-children">









  <div class="doc doc-object doc-class">



<h3 id="zenml.integrations.vllm.VLLMIntegration" class="doc doc-heading">
        <code>
VLLMIntegration            (<a class="autorefs autorefs-internal" title="zenml.integrations.integration.Integration" href="../integrations-integration/#zenml.integrations.integration.Integration">Integration</a>)
        </code>



</h3>

    <div class="doc doc-contents ">

      <p>Definition of vLLM integration for ZenML.</p>

        <details class="quote">
          <summary>Source code in <code>zenml/integrations/vllm/__init__.py</code></summary>
          <div class="highlight"><pre><span></span><code><span class="k">class</span><span class="w"> </span><span class="nc">VLLMIntegration</span><span class="p">(</span><span class="n">Integration</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Definition of vLLM integration for ZenML.&quot;&quot;&quot;</span>

    <span class="n">NAME</span> <span class="o">=</span> <span class="n">VLLM</span>

    <span class="n">REQUIREMENTS</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;vllm&gt;=0.6.0,&lt;0.7.0&quot;</span><span class="p">,</span> <span class="s2">&quot;openai&gt;=1.0.0&quot;</span><span class="p">]</span>

    <span class="nd">@classmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">activate</span><span class="p">(</span><span class="bp">cls</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Activates the integration.&quot;&quot;&quot;</span>
        <span class="kn">from</span><span class="w"> </span><span class="nn">zenml.integrations.vllm</span><span class="w"> </span><span class="kn">import</span> <span class="n">services</span>

    <span class="nd">@classmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">flavors</span><span class="p">(</span><span class="bp">cls</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">Type</span><span class="p">[</span><span class="n">Flavor</span><span class="p">]]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Declare the stack component flavors for the vLLM integration.</span>

<span class="sd">        Returns:</span>
<span class="sd">            List of stack component flavors for this integration.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="kn">from</span><span class="w"> </span><span class="nn">zenml.integrations.vllm.flavors</span><span class="w"> </span><span class="kn">import</span> <span class="n">VLLMModelDeployerFlavor</span>

        <span class="k">return</span> <span class="p">[</span><span class="n">VLLMModelDeployerFlavor</span><span class="p">]</span>
</code></pre></div>
        </details>



  <div class="doc doc-children">











  <div class="doc doc-object doc-method">



<h4 id="zenml.integrations.vllm.VLLMIntegration.activate" class="doc doc-heading">
<code class="highlight language-python"><span class="n">activate</span><span class="p">()</span></code>

  <span class="doc doc-properties">
      <small class="doc doc-property doc-property-classmethod"><code>classmethod</code></small>
  </span>

</h4>

    <div class="doc doc-contents ">

      <p>Activates the integration.</p>

        <details class="quote">
          <summary>Source code in <code>zenml/integrations/vllm/__init__.py</code></summary>
          <div class="highlight"><pre><span></span><code><span class="nd">@classmethod</span>
<span class="k">def</span><span class="w"> </span><span class="nf">activate</span><span class="p">(</span><span class="bp">cls</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Activates the integration.&quot;&quot;&quot;</span>
    <span class="kn">from</span><span class="w"> </span><span class="nn">zenml.integrations.vllm</span><span class="w"> </span><span class="kn">import</span> <span class="n">services</span>
</code></pre></div>
        </details>
    </div>

  </div>



  <div class="doc doc-object doc-method">



<h4 id="zenml.integrations.vllm.VLLMIntegration.flavors" class="doc doc-heading">
<code class="highlight language-python"><span class="n">flavors</span><span class="p">()</span></code>

  <span class="doc doc-properties">
      <small class="doc doc-property doc-property-classmethod"><code>classmethod</code></small>
  </span>

</h4>

    <div class="doc doc-contents ">

      <p>Declare the stack component flavors for the vLLM integration.</p>

<p><strong>Returns:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>List[Type[zenml.stack.flavor.Flavor]]</code></td>
      <td><p>List of stack component flavors for this integration.</p></td>
    </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>zenml/integrations/vllm/__init__.py</code></summary>
          <div class="highlight"><pre><span></span><code><span class="nd">@classmethod</span>
<span class="k">def</span><span class="w"> </span><span class="nf">flavors</span><span class="p">(</span><span class="bp">cls</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">Type</span><span class="p">[</span><span class="n">Flavor</span><span class="p">]]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Declare the stack component flavors for the vLLM integration.</span>

<span class="sd">    Returns:</span>
<span class="sd">        List of stack component flavors for this integration.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="kn">from</span><span class="w"> </span><span class="nn">zenml.integrations.vllm.flavors</span><span class="w"> </span><span class="kn">import</span> <span class="n">VLLMModelDeployerFlavor</span>

    <span class="k">return</span> <span class="p">[</span><span class="n">VLLMModelDeployerFlavor</span><span class="p">]</span>
</code></pre></div>
        </details>
    </div>

  </div>





  </div>

    </div>

  </div>






  <div class="doc doc-object doc-module">



<h3 id="zenml.integrations.vllm.flavors" class="doc doc-heading">
        <code>flavors</code>


  <span class="doc doc-properties">
      <small class="doc doc-property doc-property-special"><code>special</code></small>
  </span>

</h3>

    <div class="doc doc-contents ">

      <p>vLLM integration flavors.</p>



  <div class="doc doc-children">











  <div class="doc doc-object doc-module">



<h4 id="zenml.integrations.vllm.flavors.vllm_model_deployer_flavor" class="doc doc-heading">
        <code>vllm_model_deployer_flavor</code>



</h4>

    <div class="doc doc-contents ">

      <p>vLLM model deployer flavor.</p>



  <div class="doc doc-children">







  <div class="doc doc-object doc-class">



<h5 id="zenml.integrations.vllm.flavors.vllm_model_deployer_flavor.VLLMModelDeployerConfig" class="doc doc-heading">
        <code>
VLLMModelDeployerConfig            (<a class="autorefs autorefs-internal" title="zenml.model_deployers.base_model_deployer.BaseModelDeployerConfig" href="../../core_code_docs/core-model_deployers/#zenml.model_deployers.base_model_deployer.BaseModelDeployerConfig">BaseModelDeployerConfig</a>)
        </code>



</h5>

    <div class="doc doc-contents ">

      <p>Configuration for vLLM Inference model deployer.</p>

        <details class="quote">
          <summary>Source code in <code>zenml/integrations/vllm/flavors/vllm_model_deployer_flavor.py</code></summary>
          <div class="highlight"><pre><span></span><code><span class="k">class</span><span class="w"> </span><span class="nc">VLLMModelDeployerConfig</span><span class="p">(</span><span class="n">BaseModelDeployerConfig</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Configuration for vLLM Inference model deployer.&quot;&quot;&quot;</span>

    <span class="n">service_path</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;&quot;</span>
</code></pre></div>
        </details>



  <div class="doc doc-children">



























  </div>

    </div>

  </div>



  <div class="doc doc-object doc-class">



<h5 id="zenml.integrations.vllm.flavors.vllm_model_deployer_flavor.VLLMModelDeployerFlavor" class="doc doc-heading">
        <code>
VLLMModelDeployerFlavor            (<a class="autorefs autorefs-internal" title="zenml.model_deployers.base_model_deployer.BaseModelDeployerFlavor" href="../../core_code_docs/core-model_deployers/#zenml.model_deployers.base_model_deployer.BaseModelDeployerFlavor">BaseModelDeployerFlavor</a>)
        </code>



</h5>

    <div class="doc doc-contents ">

      <p>vLLM model deployer flavor.</p>

        <details class="quote">
          <summary>Source code in <code>zenml/integrations/vllm/flavors/vllm_model_deployer_flavor.py</code></summary>
          <div class="highlight"><pre><span></span><code><span class="k">class</span><span class="w"> </span><span class="nc">VLLMModelDeployerFlavor</span><span class="p">(</span><span class="n">BaseModelDeployerFlavor</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;vLLM model deployer flavor.&quot;&quot;&quot;</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">name</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Name of the flavor.</span>

<span class="sd">        Returns:</span>
<span class="sd">            The name of the flavor.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">VLLM_MODEL_DEPLOYER</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">docs_url</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;A url to point at docs explaining this flavor.</span>

<span class="sd">        Returns:</span>
<span class="sd">            A flavor docs url.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">generate_default_docs_url</span><span class="p">()</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">sdk_docs_url</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;A url to point at SDK docs explaining this flavor.</span>

<span class="sd">        Returns:</span>
<span class="sd">            A flavor SDK docs url.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">generate_default_sdk_docs_url</span><span class="p">()</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">logo_url</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;A url to represent the flavor in the dashboard.</span>

<span class="sd">        Returns:</span>
<span class="sd">            The flavor logo.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="s2">&quot;https://public-flavor-logos.s3.eu-central-1.amazonaws.com/model_deployer/vllm.png&quot;</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">config_class</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Type</span><span class="p">[</span><span class="n">VLLMModelDeployerConfig</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Returns `VLLMModelDeployerConfig` config class.</span>

<span class="sd">        Returns:</span>
<span class="sd">            The config class.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">VLLMModelDeployerConfig</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">implementation_class</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Type</span><span class="p">[</span><span class="s2">&quot;VLLMModelDeployer&quot;</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Implementation class for this flavor.</span>

<span class="sd">        Returns:</span>
<span class="sd">            The implementation class.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="kn">from</span><span class="w"> </span><span class="nn">zenml.integrations.vllm.model_deployers</span><span class="w"> </span><span class="kn">import</span> <span class="n">VLLMModelDeployer</span>

        <span class="k">return</span> <span class="n">VLLMModelDeployer</span>
</code></pre></div>
        </details>



  <div class="doc doc-children">






  <div class="doc doc-object doc-attribute">



<h6 id="zenml.integrations.vllm.flavors.vllm_model_deployer_flavor.VLLMModelDeployerFlavor.config_class" class="doc doc-heading">
<code class="highlight language-python"><span class="n">config_class</span><span class="p">:</span> <span class="n">Type</span><span class="p">[</span><span class="n">zenml</span><span class="o">.</span><span class="n">integrations</span><span class="o">.</span><span class="n">vllm</span><span class="o">.</span><span class="n">flavors</span><span class="o">.</span><span class="n">vllm_model_deployer_flavor</span><span class="o">.</span><span class="n">VLLMModelDeployerConfig</span><span class="p">]</span></code>

  <span class="doc doc-properties">
      <small class="doc doc-property doc-property-property"><code>property</code></small>
      <small class="doc doc-property doc-property-readonly"><code>readonly</code></small>
  </span>

</h6>

    <div class="doc doc-contents ">

      <p>Returns <code>VLLMModelDeployerConfig</code> config class.</p>

<p><strong>Returns:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>Type[zenml.integrations.vllm.flavors.vllm_model_deployer_flavor.VLLMModelDeployerConfig]</code></td>
      <td><p>The config class.</p></td>
    </tr>
  </tbody>
</table>    </div>

  </div>



  <div class="doc doc-object doc-attribute">



<h6 id="zenml.integrations.vllm.flavors.vllm_model_deployer_flavor.VLLMModelDeployerFlavor.docs_url" class="doc doc-heading">
<code class="highlight language-python"><span class="n">docs_url</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span></code>

  <span class="doc doc-properties">
      <small class="doc doc-property doc-property-property"><code>property</code></small>
      <small class="doc doc-property doc-property-readonly"><code>readonly</code></small>
  </span>

</h6>

    <div class="doc doc-contents ">

      <p>A url to point at docs explaining this flavor.</p>

<p><strong>Returns:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>Optional[str]</code></td>
      <td><p>A flavor docs url.</p></td>
    </tr>
  </tbody>
</table>    </div>

  </div>



  <div class="doc doc-object doc-attribute">



<h6 id="zenml.integrations.vllm.flavors.vllm_model_deployer_flavor.VLLMModelDeployerFlavor.implementation_class" class="doc doc-heading">
<code class="highlight language-python"><span class="n">implementation_class</span><span class="p">:</span> <span class="n">Type</span><span class="p">[</span><span class="n">VLLMModelDeployer</span><span class="p">]</span></code>

  <span class="doc doc-properties">
      <small class="doc doc-property doc-property-property"><code>property</code></small>
      <small class="doc doc-property doc-property-readonly"><code>readonly</code></small>
  </span>

</h6>

    <div class="doc doc-contents ">

      <p>Implementation class for this flavor.</p>

<p><strong>Returns:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>Type[VLLMModelDeployer]</code></td>
      <td><p>The implementation class.</p></td>
    </tr>
  </tbody>
</table>    </div>

  </div>



  <div class="doc doc-object doc-attribute">



<h6 id="zenml.integrations.vllm.flavors.vllm_model_deployer_flavor.VLLMModelDeployerFlavor.logo_url" class="doc doc-heading">
<code class="highlight language-python"><span class="n">logo_url</span><span class="p">:</span> <span class="nb">str</span></code>

  <span class="doc doc-properties">
      <small class="doc doc-property doc-property-property"><code>property</code></small>
      <small class="doc doc-property doc-property-readonly"><code>readonly</code></small>
  </span>

</h6>

    <div class="doc doc-contents ">

      <p>A url to represent the flavor in the dashboard.</p>

<p><strong>Returns:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>str</code></td>
      <td><p>The flavor logo.</p></td>
    </tr>
  </tbody>
</table>    </div>

  </div>



  <div class="doc doc-object doc-attribute">



<h6 id="zenml.integrations.vllm.flavors.vllm_model_deployer_flavor.VLLMModelDeployerFlavor.name" class="doc doc-heading">
<code class="highlight language-python"><span class="n">name</span><span class="p">:</span> <span class="nb">str</span></code>

  <span class="doc doc-properties">
      <small class="doc doc-property doc-property-property"><code>property</code></small>
      <small class="doc doc-property doc-property-readonly"><code>readonly</code></small>
  </span>

</h6>

    <div class="doc doc-contents ">

      <p>Name of the flavor.</p>

<p><strong>Returns:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>str</code></td>
      <td><p>The name of the flavor.</p></td>
    </tr>
  </tbody>
</table>    </div>

  </div>



  <div class="doc doc-object doc-attribute">



<h6 id="zenml.integrations.vllm.flavors.vllm_model_deployer_flavor.VLLMModelDeployerFlavor.sdk_docs_url" class="doc doc-heading">
<code class="highlight language-python"><span class="n">sdk_docs_url</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span></code>

  <span class="doc doc-properties">
      <small class="doc doc-property doc-property-property"><code>property</code></small>
      <small class="doc doc-property doc-property-readonly"><code>readonly</code></small>
  </span>

</h6>

    <div class="doc doc-contents ">

      <p>A url to point at SDK docs explaining this flavor.</p>

<p><strong>Returns:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>Optional[str]</code></td>
      <td><p>A flavor SDK docs url.</p></td>
    </tr>
  </tbody>
</table>    </div>

  </div>








  </div>

    </div>

  </div>







  </div>

    </div>

  </div>




  </div>

    </div>

  </div>



  <div class="doc doc-object doc-module">



<h3 id="zenml.integrations.vllm.model_deployers" class="doc doc-heading">
        <code>model_deployers</code>


  <span class="doc doc-properties">
      <small class="doc doc-property doc-property-special"><code>special</code></small>
  </span>

</h3>

    <div class="doc doc-contents ">

      <p>Initialization of the vLLM model deployers.</p>



  <div class="doc doc-children">











  <div class="doc doc-object doc-module">



<h4 id="zenml.integrations.vllm.model_deployers.vllm_model_deployer" class="doc doc-heading">
        <code>vllm_model_deployer</code>



</h4>

    <div class="doc doc-contents ">

      <p>Implementation of the vLLM Model Deployer.</p>



  <div class="doc doc-children">








  <div class="doc doc-object doc-class">



<h5 id="zenml.integrations.vllm.model_deployers.vllm_model_deployer.VLLMModelDeployer" class="doc doc-heading">
        <code>
VLLMModelDeployer            (<a class="autorefs autorefs-internal" title="zenml.model_deployers.base_model_deployer.BaseModelDeployer" href="../../core_code_docs/core-model_deployers/#zenml.model_deployers.base_model_deployer.BaseModelDeployer">BaseModelDeployer</a>)
        </code>



</h5>

    <div class="doc doc-contents ">

      <p>vLLM Inference Server.</p>

        <details class="quote">
          <summary>Source code in <code>zenml/integrations/vllm/model_deployers/vllm_model_deployer.py</code></summary>
          <div class="highlight"><pre><span></span><code><span class="k">class</span><span class="w"> </span><span class="nc">VLLMModelDeployer</span><span class="p">(</span><span class="n">BaseModelDeployer</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;vLLM Inference Server.&quot;&quot;&quot;</span>

    <span class="n">NAME</span><span class="p">:</span> <span class="n">ClassVar</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;VLLM&quot;</span>
    <span class="n">FLAVOR</span><span class="p">:</span> <span class="n">ClassVar</span><span class="p">[</span><span class="n">Type</span><span class="p">[</span><span class="n">BaseModelDeployerFlavor</span><span class="p">]]</span> <span class="o">=</span> <span class="n">VLLMModelDeployerFlavor</span>

    <span class="n">_service_path</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">config</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">VLLMModelDeployerConfig</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Returns the `VLLMModelDeployerConfig` config.</span>

<span class="sd">        Returns:</span>
<span class="sd">            The configuration.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">cast</span><span class="p">(</span><span class="n">VLLMModelDeployerConfig</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_config</span><span class="p">)</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">get_service_path</span><span class="p">(</span><span class="n">id_</span><span class="p">:</span> <span class="n">UUID</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Get the path where local vLLM service information is stored.</span>

<span class="sd">        This includes the deployment service configuration, PID and log files</span>
<span class="sd">        are stored.</span>

<span class="sd">        Args:</span>
<span class="sd">            id_: The ID of the vLLM model deployer.</span>

<span class="sd">        Returns:</span>
<span class="sd">            The service path.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">service_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span>
            <span class="n">GlobalConfiguration</span><span class="p">()</span><span class="o">.</span><span class="n">local_stores_path</span><span class="p">,</span>
            <span class="nb">str</span><span class="p">(</span><span class="n">id_</span><span class="p">),</span>
        <span class="p">)</span>
        <span class="n">create_dir_recursive_if_not_exists</span><span class="p">(</span><span class="n">service_path</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">service_path</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">local_path</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Returns the path to the root directory.</span>

<span class="sd">        This is where all configurations for vLLM deployment daemon processes</span>
<span class="sd">        are stored.</span>

<span class="sd">        If the service path is not set in the config by the user, the path is</span>
<span class="sd">        set to a local default path according to the component ID.</span>

<span class="sd">        Returns:</span>
<span class="sd">            The path to the local service root directory.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_service_path</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_service_path</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">service_path</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_service_path</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">service_path</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_service_path</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_service_path</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">id</span><span class="p">)</span>

        <span class="n">create_dir_recursive_if_not_exists</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_service_path</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_service_path</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">get_model_server_info</span><span class="p">(</span>  <span class="c1"># type: ignore[override]</span>
        <span class="n">service_instance</span><span class="p">:</span> <span class="s2">&quot;VLLMDeploymentService&quot;</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Return implementation specific information on the model server.</span>

<span class="sd">        Args:</span>
<span class="sd">            service_instance: vLLM deployment service object</span>

<span class="sd">        Returns:</span>
<span class="sd">            A dictionary containing the model server information.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="p">{</span>
            <span class="s2">&quot;HEALTH_CHECK_URL&quot;</span><span class="p">:</span> <span class="n">service_instance</span><span class="o">.</span><span class="n">get_healthcheck_url</span><span class="p">(),</span>
            <span class="s2">&quot;PREDICTION_URL&quot;</span><span class="p">:</span> <span class="n">service_instance</span><span class="o">.</span><span class="n">get_prediction_url</span><span class="p">(),</span>
            <span class="s2">&quot;SERVICE_PATH&quot;</span><span class="p">:</span> <span class="n">service_instance</span><span class="o">.</span><span class="n">status</span><span class="o">.</span><span class="n">runtime_path</span><span class="p">,</span>
            <span class="s2">&quot;DAEMON_PID&quot;</span><span class="p">:</span> <span class="nb">str</span><span class="p">(</span><span class="n">service_instance</span><span class="o">.</span><span class="n">status</span><span class="o">.</span><span class="n">pid</span><span class="p">),</span>
        <span class="p">}</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">perform_deploy_model</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="nb">id</span><span class="p">:</span> <span class="n">UUID</span><span class="p">,</span>
        <span class="n">config</span><span class="p">:</span> <span class="n">ServiceConfig</span><span class="p">,</span>
        <span class="n">timeout</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="n">DEFAULT_SERVICE_START_STOP_TIMEOUT</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">BaseService</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Create a new vLLM deployment service or update an existing one.</span>

<span class="sd">        This should serve the supplied model and deployment configuration.</span>

<span class="sd">        This method has two modes of operation, depending on the `replace`</span>
<span class="sd">        argument value:</span>

<span class="sd">          * if `replace` is False, calling this method will create a new vLLM</span>
<span class="sd">            deployment server to reflect the model and other configuration</span>
<span class="sd">            parameters specified in the supplied vLLM service `config`.</span>

<span class="sd">          * if `replace` is True, this method will first attempt to find an</span>
<span class="sd">            existing vLLM deployment service that is *equivalent* to the</span>
<span class="sd">            supplied configuration parameters. Two or more vLLM deployment</span>
<span class="sd">            services are considered equivalent if they have the same</span>
<span class="sd">            `pipeline_name`, `pipeline_step_name` and `model_name` configuration</span>
<span class="sd">            parameters. To put it differently, two vLLM deployment services</span>
<span class="sd">            are equivalent if they serve versions of the same model deployed by</span>
<span class="sd">            the same pipeline step. If an equivalent vLLM deployment is found,</span>
<span class="sd">            it will be updated in place to reflect the new configuration</span>
<span class="sd">            parameters.</span>

<span class="sd">        Callers should set `replace` to True if they want a continuous model</span>
<span class="sd">        deployment workflow that doesn&#39;t spin up a new vLLM deployment</span>
<span class="sd">        server for each new model version. If multiple equivalent vLLM</span>
<span class="sd">        deployment servers are found, one is selected at random to be updated</span>
<span class="sd">        and the others are deleted.</span>

<span class="sd">        Args:</span>
<span class="sd">            id: the UUID of the vLLM model deployer.</span>
<span class="sd">            config: the configuration of the model to be deployed with vLLM.</span>
<span class="sd">            timeout: the timeout in seconds to wait for the vLLM server</span>
<span class="sd">                to be provisioned and successfully started or updated. If set</span>
<span class="sd">                to 0, the method will return immediately after the vLLM</span>
<span class="sd">                server is provisioned, without waiting for it to fully start.</span>

<span class="sd">        Returns:</span>
<span class="sd">            The ZenML vLLM deployment service object that can be used to</span>
<span class="sd">            interact with the vLLM model http server.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">config</span> <span class="o">=</span> <span class="n">cast</span><span class="p">(</span><span class="n">VLLMServiceConfig</span><span class="p">,</span> <span class="n">config</span><span class="p">)</span>
        <span class="n">service</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_create_new_service</span><span class="p">(</span>
            <span class="nb">id</span><span class="o">=</span><span class="nb">id</span><span class="p">,</span> <span class="n">timeout</span><span class="o">=</span><span class="n">timeout</span><span class="p">,</span> <span class="n">config</span><span class="o">=</span><span class="n">config</span>
        <span class="p">)</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Created a new vLLM deployment service: </span><span class="si">{</span><span class="n">service</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">service</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_clean_up_existing_service</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">timeout</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">force</span><span class="p">:</span> <span class="nb">bool</span><span class="p">,</span>
        <span class="n">existing_service</span><span class="p">:</span> <span class="n">VLLMDeploymentService</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="c1"># stop the older service</span>
        <span class="n">existing_service</span><span class="o">.</span><span class="n">stop</span><span class="p">(</span><span class="n">timeout</span><span class="o">=</span><span class="n">timeout</span><span class="p">,</span> <span class="n">force</span><span class="o">=</span><span class="n">force</span><span class="p">)</span>

        <span class="c1"># delete the old configuration file</span>
        <span class="k">if</span> <span class="n">existing_service</span><span class="o">.</span><span class="n">status</span><span class="o">.</span><span class="n">runtime_path</span><span class="p">:</span>
            <span class="n">shutil</span><span class="o">.</span><span class="n">rmtree</span><span class="p">(</span><span class="n">existing_service</span><span class="o">.</span><span class="n">status</span><span class="o">.</span><span class="n">runtime_path</span><span class="p">)</span>

    <span class="c1"># the step will receive a config from the user that mentions the number</span>
    <span class="c1"># of workers etc.the step implementation will create a new config using</span>
    <span class="c1"># all values from the user and add values like pipeline name, model_uri</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">_create_new_service</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="nb">id</span><span class="p">:</span> <span class="n">UUID</span><span class="p">,</span> <span class="n">timeout</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">config</span><span class="p">:</span> <span class="n">VLLMServiceConfig</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">VLLMDeploymentService</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Creates a new VLLMDeploymentService.</span>

<span class="sd">        Args:</span>
<span class="sd">            id: the ID of the vLLM deployment service to be created or updated.</span>
<span class="sd">            timeout: the timeout in seconds to wait for the vLLM server</span>
<span class="sd">                to be provisioned and successfully started or updated.</span>
<span class="sd">            config: the configuration of the model to be deployed with vLLM.</span>

<span class="sd">        Returns:</span>
<span class="sd">            The VLLMDeploymentService object that can be used to interact</span>
<span class="sd">            with the vLLM model server.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># set the root runtime path with the stack component&#39;s UUID</span>
        <span class="n">config</span><span class="o">.</span><span class="n">root_runtime_path</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">local_path</span>
        <span class="c1"># create a new service for the new model</span>
        <span class="n">service</span> <span class="o">=</span> <span class="n">VLLMDeploymentService</span><span class="p">(</span><span class="n">uuid</span><span class="o">=</span><span class="nb">id</span><span class="p">,</span> <span class="n">config</span><span class="o">=</span><span class="n">config</span><span class="p">)</span>
        <span class="n">service</span><span class="o">.</span><span class="n">start</span><span class="p">(</span><span class="n">timeout</span><span class="o">=</span><span class="n">timeout</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">service</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">perform_stop_model</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">service</span><span class="p">:</span> <span class="n">BaseService</span><span class="p">,</span>
        <span class="n">timeout</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="n">DEFAULT_SERVICE_START_STOP_TIMEOUT</span><span class="p">,</span>
        <span class="n">force</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">BaseService</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Method to stop a model server.</span>

<span class="sd">        Args:</span>
<span class="sd">            service: The service to stop.</span>
<span class="sd">            timeout: Timeout in seconds to wait for the service to stop.</span>
<span class="sd">            force: If True, force the service to stop.</span>

<span class="sd">        Returns:</span>
<span class="sd">            The stopped service.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">service</span><span class="o">.</span><span class="n">stop</span><span class="p">(</span><span class="n">timeout</span><span class="o">=</span><span class="n">timeout</span><span class="p">,</span> <span class="n">force</span><span class="o">=</span><span class="n">force</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">service</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">perform_start_model</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">service</span><span class="p">:</span> <span class="n">BaseService</span><span class="p">,</span>
        <span class="n">timeout</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="n">DEFAULT_SERVICE_START_STOP_TIMEOUT</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">BaseService</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Method to start a model server.</span>

<span class="sd">        Args:</span>
<span class="sd">            service: The service to start.</span>
<span class="sd">            timeout: Timeout in seconds to wait for the service to start.</span>

<span class="sd">        Returns:</span>
<span class="sd">            The started service.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">service</span><span class="o">.</span><span class="n">start</span><span class="p">(</span><span class="n">timeout</span><span class="o">=</span><span class="n">timeout</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">service</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">perform_delete_model</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">service</span><span class="p">:</span> <span class="n">BaseService</span><span class="p">,</span>
        <span class="n">timeout</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="n">DEFAULT_SERVICE_START_STOP_TIMEOUT</span><span class="p">,</span>
        <span class="n">force</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Method to delete all configuration of a model server.</span>

<span class="sd">        Args:</span>
<span class="sd">            service: The service to delete.</span>
<span class="sd">            timeout: Timeout in seconds to wait for the service to stop.</span>
<span class="sd">            force: If True, force the service to stop.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">service</span> <span class="o">=</span> <span class="n">cast</span><span class="p">(</span><span class="n">VLLMDeploymentService</span><span class="p">,</span> <span class="n">service</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_clean_up_existing_service</span><span class="p">(</span>
            <span class="n">existing_service</span><span class="o">=</span><span class="n">service</span><span class="p">,</span> <span class="n">timeout</span><span class="o">=</span><span class="n">timeout</span><span class="p">,</span> <span class="n">force</span><span class="o">=</span><span class="n">force</span>
        <span class="p">)</span>
</code></pre></div>
        </details>



  <div class="doc doc-children">







  <div class="doc doc-object doc-attribute">



<h6 id="zenml.integrations.vllm.model_deployers.vllm_model_deployer.VLLMModelDeployer.config" class="doc doc-heading">
<code class="highlight language-python"><span class="n">config</span><span class="p">:</span> <span class="n">VLLMModelDeployerConfig</span></code>

  <span class="doc doc-properties">
      <small class="doc doc-property doc-property-property"><code>property</code></small>
      <small class="doc doc-property doc-property-readonly"><code>readonly</code></small>
  </span>

</h6>

    <div class="doc doc-contents ">

      <p>Returns the <code>VLLMModelDeployerConfig</code> config.</p>

<p><strong>Returns:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>VLLMModelDeployerConfig</code></td>
      <td><p>The configuration.</p></td>
    </tr>
  </tbody>
</table>    </div>

  </div>



  <div class="doc doc-object doc-attribute">



<h6 id="zenml.integrations.vllm.model_deployers.vllm_model_deployer.VLLMModelDeployer.local_path" class="doc doc-heading">
<code class="highlight language-python"><span class="n">local_path</span><span class="p">:</span> <span class="nb">str</span></code>

  <span class="doc doc-properties">
      <small class="doc doc-property doc-property-property"><code>property</code></small>
      <small class="doc doc-property doc-property-readonly"><code>readonly</code></small>
  </span>

</h6>

    <div class="doc doc-contents ">

      <p>Returns the path to the root directory.</p>
<p>This is where all configurations for vLLM deployment daemon processes
are stored.</p>
<p>If the service path is not set in the config by the user, the path is
set to a local default path according to the component ID.</p>

<p><strong>Returns:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>str</code></td>
      <td><p>The path to the local service root directory.</p></td>
    </tr>
  </tbody>
</table>    </div>

  </div>




  <div class="doc doc-object doc-class">



<h6 id="zenml.integrations.vllm.model_deployers.vllm_model_deployer.VLLMModelDeployer.FLAVOR" class="doc doc-heading">
        <code>
FLAVOR            (<a class="autorefs autorefs-internal" title="zenml.model_deployers.base_model_deployer.BaseModelDeployerFlavor" href="../../core_code_docs/core-model_deployers/#zenml.model_deployers.base_model_deployer.BaseModelDeployerFlavor">BaseModelDeployerFlavor</a>)
        </code>



</h6>

    <div class="doc doc-contents ">

      <p>vLLM model deployer flavor.</p>

        <details class="quote">
          <summary>Source code in <code>zenml/integrations/vllm/model_deployers/vllm_model_deployer.py</code></summary>
          <div class="highlight"><pre><span></span><code><span class="k">class</span><span class="w"> </span><span class="nc">VLLMModelDeployerFlavor</span><span class="p">(</span><span class="n">BaseModelDeployerFlavor</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;vLLM model deployer flavor.&quot;&quot;&quot;</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">name</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Name of the flavor.</span>

<span class="sd">        Returns:</span>
<span class="sd">            The name of the flavor.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">VLLM_MODEL_DEPLOYER</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">docs_url</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;A url to point at docs explaining this flavor.</span>

<span class="sd">        Returns:</span>
<span class="sd">            A flavor docs url.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">generate_default_docs_url</span><span class="p">()</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">sdk_docs_url</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;A url to point at SDK docs explaining this flavor.</span>

<span class="sd">        Returns:</span>
<span class="sd">            A flavor SDK docs url.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">generate_default_sdk_docs_url</span><span class="p">()</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">logo_url</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;A url to represent the flavor in the dashboard.</span>

<span class="sd">        Returns:</span>
<span class="sd">            The flavor logo.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="s2">&quot;https://public-flavor-logos.s3.eu-central-1.amazonaws.com/model_deployer/vllm.png&quot;</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">config_class</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Type</span><span class="p">[</span><span class="n">VLLMModelDeployerConfig</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Returns `VLLMModelDeployerConfig` config class.</span>

<span class="sd">        Returns:</span>
<span class="sd">            The config class.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">VLLMModelDeployerConfig</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">implementation_class</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Type</span><span class="p">[</span><span class="s2">&quot;VLLMModelDeployer&quot;</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Implementation class for this flavor.</span>

<span class="sd">        Returns:</span>
<span class="sd">            The implementation class.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="kn">from</span><span class="w"> </span><span class="nn">zenml.integrations.vllm.model_deployers</span><span class="w"> </span><span class="kn">import</span> <span class="n">VLLMModelDeployer</span>

        <span class="k">return</span> <span class="n">VLLMModelDeployer</span>
</code></pre></div>
        </details>



  <div class="doc doc-children">






  <div class="doc doc-object doc-attribute">



<h7 id="zenml.integrations.vllm.model_deployers.vllm_model_deployer.VLLMModelDeployer.FLAVOR.config_class" class="doc doc-heading">
<code class="highlight language-python"><span class="n">config_class</span><span class="p">:</span> <span class="n">Type</span><span class="p">[</span><span class="n">zenml</span><span class="o">.</span><span class="n">integrations</span><span class="o">.</span><span class="n">vllm</span><span class="o">.</span><span class="n">flavors</span><span class="o">.</span><span class="n">vllm_model_deployer_flavor</span><span class="o">.</span><span class="n">VLLMModelDeployerConfig</span><span class="p">]</span></code>

  <span class="doc doc-properties">
      <small class="doc doc-property doc-property-property"><code>property</code></small>
      <small class="doc doc-property doc-property-readonly"><code>readonly</code></small>
  </span>

</h7>

    <div class="doc doc-contents ">

      <p>Returns <code>VLLMModelDeployerConfig</code> config class.</p>

<p><strong>Returns:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>Type[zenml.integrations.vllm.flavors.vllm_model_deployer_flavor.VLLMModelDeployerConfig]</code></td>
      <td><p>The config class.</p></td>
    </tr>
  </tbody>
</table>    </div>

  </div>



  <div class="doc doc-object doc-attribute">



<h7 id="zenml.integrations.vllm.model_deployers.vllm_model_deployer.VLLMModelDeployer.FLAVOR.docs_url" class="doc doc-heading">
<code class="highlight language-python"><span class="n">docs_url</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span></code>

  <span class="doc doc-properties">
      <small class="doc doc-property doc-property-property"><code>property</code></small>
      <small class="doc doc-property doc-property-readonly"><code>readonly</code></small>
  </span>

</h7>

    <div class="doc doc-contents ">

      <p>A url to point at docs explaining this flavor.</p>

<p><strong>Returns:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>Optional[str]</code></td>
      <td><p>A flavor docs url.</p></td>
    </tr>
  </tbody>
</table>    </div>

  </div>



  <div class="doc doc-object doc-attribute">



<h7 id="zenml.integrations.vllm.model_deployers.vllm_model_deployer.VLLMModelDeployer.FLAVOR.implementation_class" class="doc doc-heading">
<code class="highlight language-python"><span class="n">implementation_class</span><span class="p">:</span> <span class="n">Type</span><span class="p">[</span><span class="n">VLLMModelDeployer</span><span class="p">]</span></code>

  <span class="doc doc-properties">
      <small class="doc doc-property doc-property-property"><code>property</code></small>
      <small class="doc doc-property doc-property-readonly"><code>readonly</code></small>
  </span>

</h7>

    <div class="doc doc-contents ">

      <p>Implementation class for this flavor.</p>

<p><strong>Returns:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>Type[VLLMModelDeployer]</code></td>
      <td><p>The implementation class.</p></td>
    </tr>
  </tbody>
</table>    </div>

  </div>



  <div class="doc doc-object doc-attribute">



<h7 id="zenml.integrations.vllm.model_deployers.vllm_model_deployer.VLLMModelDeployer.FLAVOR.logo_url" class="doc doc-heading">
<code class="highlight language-python"><span class="n">logo_url</span><span class="p">:</span> <span class="nb">str</span></code>

  <span class="doc doc-properties">
      <small class="doc doc-property doc-property-property"><code>property</code></small>
      <small class="doc doc-property doc-property-readonly"><code>readonly</code></small>
  </span>

</h7>

    <div class="doc doc-contents ">

      <p>A url to represent the flavor in the dashboard.</p>

<p><strong>Returns:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>str</code></td>
      <td><p>The flavor logo.</p></td>
    </tr>
  </tbody>
</table>    </div>

  </div>



  <div class="doc doc-object doc-attribute">



<h7 id="zenml.integrations.vllm.model_deployers.vllm_model_deployer.VLLMModelDeployer.FLAVOR.name" class="doc doc-heading">
<code class="highlight language-python"><span class="n">name</span><span class="p">:</span> <span class="nb">str</span></code>

  <span class="doc doc-properties">
      <small class="doc doc-property doc-property-property"><code>property</code></small>
      <small class="doc doc-property doc-property-readonly"><code>readonly</code></small>
  </span>

</h7>

    <div class="doc doc-contents ">

      <p>Name of the flavor.</p>

<p><strong>Returns:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>str</code></td>
      <td><p>The name of the flavor.</p></td>
    </tr>
  </tbody>
</table>    </div>

  </div>



  <div class="doc doc-object doc-attribute">



<h7 id="zenml.integrations.vllm.model_deployers.vllm_model_deployer.VLLMModelDeployer.FLAVOR.sdk_docs_url" class="doc doc-heading">
<code class="highlight language-python"><span class="n">sdk_docs_url</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span></code>

  <span class="doc doc-properties">
      <small class="doc doc-property doc-property-property"><code>property</code></small>
      <small class="doc doc-property doc-property-readonly"><code>readonly</code></small>
  </span>

</h7>

    <div class="doc doc-contents ">

      <p>A url to point at SDK docs explaining this flavor.</p>

<p><strong>Returns:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>Optional[str]</code></td>
      <td><p>A flavor SDK docs url.</p></td>
    </tr>
  </tbody>
</table>    </div>

  </div>








  </div>

    </div>

  </div>





  <div class="doc doc-object doc-method">



<h6 id="zenml.integrations.vllm.model_deployers.vllm_model_deployer.VLLMModelDeployer.get_model_server_info" class="doc doc-heading">
<code class="highlight language-python"><span class="n">get_model_server_info</span><span class="p">(</span><span class="n">service_instance</span><span class="p">)</span></code>

  <span class="doc doc-properties">
      <small class="doc doc-property doc-property-staticmethod"><code>staticmethod</code></small>
  </span>

</h6>

    <div class="doc doc-contents ">

      <p>Return implementation specific information on the model server.</p>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>service_instance</code></td>
        <td><code>VLLMDeploymentService</code></td>
        <td><p>vLLM deployment service object</p></td>
        <td><em>required</em></td>
      </tr>
  </tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>Dict[str, Optional[str]]</code></td>
      <td><p>A dictionary containing the model server information.</p></td>
    </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>zenml/integrations/vllm/model_deployers/vllm_model_deployer.py</code></summary>
          <div class="highlight"><pre><span></span><code><span class="nd">@staticmethod</span>
<span class="k">def</span><span class="w"> </span><span class="nf">get_model_server_info</span><span class="p">(</span>  <span class="c1"># type: ignore[override]</span>
    <span class="n">service_instance</span><span class="p">:</span> <span class="s2">&quot;VLLMDeploymentService&quot;</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Return implementation specific information on the model server.</span>

<span class="sd">    Args:</span>
<span class="sd">        service_instance: vLLM deployment service object</span>

<span class="sd">    Returns:</span>
<span class="sd">        A dictionary containing the model server information.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="p">{</span>
        <span class="s2">&quot;HEALTH_CHECK_URL&quot;</span><span class="p">:</span> <span class="n">service_instance</span><span class="o">.</span><span class="n">get_healthcheck_url</span><span class="p">(),</span>
        <span class="s2">&quot;PREDICTION_URL&quot;</span><span class="p">:</span> <span class="n">service_instance</span><span class="o">.</span><span class="n">get_prediction_url</span><span class="p">(),</span>
        <span class="s2">&quot;SERVICE_PATH&quot;</span><span class="p">:</span> <span class="n">service_instance</span><span class="o">.</span><span class="n">status</span><span class="o">.</span><span class="n">runtime_path</span><span class="p">,</span>
        <span class="s2">&quot;DAEMON_PID&quot;</span><span class="p">:</span> <span class="nb">str</span><span class="p">(</span><span class="n">service_instance</span><span class="o">.</span><span class="n">status</span><span class="o">.</span><span class="n">pid</span><span class="p">),</span>
    <span class="p">}</span>
</code></pre></div>
        </details>
    </div>

  </div>



  <div class="doc doc-object doc-method">



<h6 id="zenml.integrations.vllm.model_deployers.vllm_model_deployer.VLLMModelDeployer.get_service_path" class="doc doc-heading">
<code class="highlight language-python"><span class="n">get_service_path</span><span class="p">(</span><span class="n">id_</span><span class="p">)</span></code>

  <span class="doc doc-properties">
      <small class="doc doc-property doc-property-staticmethod"><code>staticmethod</code></small>
  </span>

</h6>

    <div class="doc doc-contents ">

      <p>Get the path where local vLLM service information is stored.</p>
<p>This includes the deployment service configuration, PID and log files
are stored.</p>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>id_</code></td>
        <td><code>UUID</code></td>
        <td><p>The ID of the vLLM model deployer.</p></td>
        <td><em>required</em></td>
      </tr>
  </tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>str</code></td>
      <td><p>The service path.</p></td>
    </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>zenml/integrations/vllm/model_deployers/vllm_model_deployer.py</code></summary>
          <div class="highlight"><pre><span></span><code><span class="nd">@staticmethod</span>
<span class="k">def</span><span class="w"> </span><span class="nf">get_service_path</span><span class="p">(</span><span class="n">id_</span><span class="p">:</span> <span class="n">UUID</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Get the path where local vLLM service information is stored.</span>

<span class="sd">    This includes the deployment service configuration, PID and log files</span>
<span class="sd">    are stored.</span>

<span class="sd">    Args:</span>
<span class="sd">        id_: The ID of the vLLM model deployer.</span>

<span class="sd">    Returns:</span>
<span class="sd">        The service path.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">service_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span>
        <span class="n">GlobalConfiguration</span><span class="p">()</span><span class="o">.</span><span class="n">local_stores_path</span><span class="p">,</span>
        <span class="nb">str</span><span class="p">(</span><span class="n">id_</span><span class="p">),</span>
    <span class="p">)</span>
    <span class="n">create_dir_recursive_if_not_exists</span><span class="p">(</span><span class="n">service_path</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">service_path</span>
</code></pre></div>
        </details>
    </div>

  </div>



  <div class="doc doc-object doc-method">



<h6 id="zenml.integrations.vllm.model_deployers.vllm_model_deployer.VLLMModelDeployer.perform_delete_model" class="doc doc-heading">
<code class="highlight language-python"><span class="n">perform_delete_model</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">service</span><span class="p">,</span> <span class="n">timeout</span><span class="o">=</span><span class="mi">60</span><span class="p">,</span> <span class="n">force</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span></code>


</h6>

    <div class="doc doc-contents ">

      <p>Method to delete all configuration of a model server.</p>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>service</code></td>
        <td><code>BaseService</code></td>
        <td><p>The service to delete.</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>timeout</code></td>
        <td><code>int</code></td>
        <td><p>Timeout in seconds to wait for the service to stop.</p></td>
        <td><code>60</code></td>
      </tr>
      <tr>
        <td><code>force</code></td>
        <td><code>bool</code></td>
        <td><p>If True, force the service to stop.</p></td>
        <td><code>False</code></td>
      </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>zenml/integrations/vllm/model_deployers/vllm_model_deployer.py</code></summary>
          <div class="highlight"><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">perform_delete_model</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">service</span><span class="p">:</span> <span class="n">BaseService</span><span class="p">,</span>
    <span class="n">timeout</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="n">DEFAULT_SERVICE_START_STOP_TIMEOUT</span><span class="p">,</span>
    <span class="n">force</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Method to delete all configuration of a model server.</span>

<span class="sd">    Args:</span>
<span class="sd">        service: The service to delete.</span>
<span class="sd">        timeout: Timeout in seconds to wait for the service to stop.</span>
<span class="sd">        force: If True, force the service to stop.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">service</span> <span class="o">=</span> <span class="n">cast</span><span class="p">(</span><span class="n">VLLMDeploymentService</span><span class="p">,</span> <span class="n">service</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_clean_up_existing_service</span><span class="p">(</span>
        <span class="n">existing_service</span><span class="o">=</span><span class="n">service</span><span class="p">,</span> <span class="n">timeout</span><span class="o">=</span><span class="n">timeout</span><span class="p">,</span> <span class="n">force</span><span class="o">=</span><span class="n">force</span>
    <span class="p">)</span>
</code></pre></div>
        </details>
    </div>

  </div>



  <div class="doc doc-object doc-method">



<h6 id="zenml.integrations.vllm.model_deployers.vllm_model_deployer.VLLMModelDeployer.perform_deploy_model" class="doc doc-heading">
<code class="highlight language-python"><span class="n">perform_deploy_model</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="nb">id</span><span class="p">,</span> <span class="n">config</span><span class="p">,</span> <span class="n">timeout</span><span class="o">=</span><span class="mi">60</span><span class="p">)</span></code>


</h6>

    <div class="doc doc-contents ">

      <p>Create a new vLLM deployment service or update an existing one.</p>
<p>This should serve the supplied model and deployment configuration.</p>
<p>This method has two modes of operation, depending on the <code>replace</code>
argument value:</p>
<ul>
<li>
<p>if <code>replace</code> is False, calling this method will create a new vLLM
    deployment server to reflect the model and other configuration
    parameters specified in the supplied vLLM service <code>config</code>.</p>
</li>
<li>
<p>if <code>replace</code> is True, this method will first attempt to find an
    existing vLLM deployment service that is <em>equivalent</em> to the
    supplied configuration parameters. Two or more vLLM deployment
    services are considered equivalent if they have the same
    <code>pipeline_name</code>, <code>pipeline_step_name</code> and <code>model_name</code> configuration
    parameters. To put it differently, two vLLM deployment services
    are equivalent if they serve versions of the same model deployed by
    the same pipeline step. If an equivalent vLLM deployment is found,
    it will be updated in place to reflect the new configuration
    parameters.</p>
</li>
</ul>
<p>Callers should set <code>replace</code> to True if they want a continuous model
deployment workflow that doesn't spin up a new vLLM deployment
server for each new model version. If multiple equivalent vLLM
deployment servers are found, one is selected at random to be updated
and the others are deleted.</p>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>id</code></td>
        <td><code>UUID</code></td>
        <td><p>the UUID of the vLLM model deployer.</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>config</code></td>
        <td><code>ServiceConfig</code></td>
        <td><p>the configuration of the model to be deployed with vLLM.</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>timeout</code></td>
        <td><code>int</code></td>
        <td><p>the timeout in seconds to wait for the vLLM server
to be provisioned and successfully started or updated. If set
to 0, the method will return immediately after the vLLM
server is provisioned, without waiting for it to fully start.</p></td>
        <td><code>60</code></td>
      </tr>
  </tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>BaseService</code></td>
      <td><p>The ZenML vLLM deployment service object that can be used to
interact with the vLLM model http server.</p></td>
    </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>zenml/integrations/vllm/model_deployers/vllm_model_deployer.py</code></summary>
          <div class="highlight"><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">perform_deploy_model</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="nb">id</span><span class="p">:</span> <span class="n">UUID</span><span class="p">,</span>
    <span class="n">config</span><span class="p">:</span> <span class="n">ServiceConfig</span><span class="p">,</span>
    <span class="n">timeout</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="n">DEFAULT_SERVICE_START_STOP_TIMEOUT</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">BaseService</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Create a new vLLM deployment service or update an existing one.</span>

<span class="sd">    This should serve the supplied model and deployment configuration.</span>

<span class="sd">    This method has two modes of operation, depending on the `replace`</span>
<span class="sd">    argument value:</span>

<span class="sd">      * if `replace` is False, calling this method will create a new vLLM</span>
<span class="sd">        deployment server to reflect the model and other configuration</span>
<span class="sd">        parameters specified in the supplied vLLM service `config`.</span>

<span class="sd">      * if `replace` is True, this method will first attempt to find an</span>
<span class="sd">        existing vLLM deployment service that is *equivalent* to the</span>
<span class="sd">        supplied configuration parameters. Two or more vLLM deployment</span>
<span class="sd">        services are considered equivalent if they have the same</span>
<span class="sd">        `pipeline_name`, `pipeline_step_name` and `model_name` configuration</span>
<span class="sd">        parameters. To put it differently, two vLLM deployment services</span>
<span class="sd">        are equivalent if they serve versions of the same model deployed by</span>
<span class="sd">        the same pipeline step. If an equivalent vLLM deployment is found,</span>
<span class="sd">        it will be updated in place to reflect the new configuration</span>
<span class="sd">        parameters.</span>

<span class="sd">    Callers should set `replace` to True if they want a continuous model</span>
<span class="sd">    deployment workflow that doesn&#39;t spin up a new vLLM deployment</span>
<span class="sd">    server for each new model version. If multiple equivalent vLLM</span>
<span class="sd">    deployment servers are found, one is selected at random to be updated</span>
<span class="sd">    and the others are deleted.</span>

<span class="sd">    Args:</span>
<span class="sd">        id: the UUID of the vLLM model deployer.</span>
<span class="sd">        config: the configuration of the model to be deployed with vLLM.</span>
<span class="sd">        timeout: the timeout in seconds to wait for the vLLM server</span>
<span class="sd">            to be provisioned and successfully started or updated. If set</span>
<span class="sd">            to 0, the method will return immediately after the vLLM</span>
<span class="sd">            server is provisioned, without waiting for it to fully start.</span>

<span class="sd">    Returns:</span>
<span class="sd">        The ZenML vLLM deployment service object that can be used to</span>
<span class="sd">        interact with the vLLM model http server.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">config</span> <span class="o">=</span> <span class="n">cast</span><span class="p">(</span><span class="n">VLLMServiceConfig</span><span class="p">,</span> <span class="n">config</span><span class="p">)</span>
    <span class="n">service</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_create_new_service</span><span class="p">(</span>
        <span class="nb">id</span><span class="o">=</span><span class="nb">id</span><span class="p">,</span> <span class="n">timeout</span><span class="o">=</span><span class="n">timeout</span><span class="p">,</span> <span class="n">config</span><span class="o">=</span><span class="n">config</span>
    <span class="p">)</span>
    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Created a new vLLM deployment service: </span><span class="si">{</span><span class="n">service</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">service</span>
</code></pre></div>
        </details>
    </div>

  </div>



  <div class="doc doc-object doc-method">



<h6 id="zenml.integrations.vllm.model_deployers.vllm_model_deployer.VLLMModelDeployer.perform_start_model" class="doc doc-heading">
<code class="highlight language-python"><span class="n">perform_start_model</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">service</span><span class="p">,</span> <span class="n">timeout</span><span class="o">=</span><span class="mi">60</span><span class="p">)</span></code>


</h6>

    <div class="doc doc-contents ">

      <p>Method to start a model server.</p>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>service</code></td>
        <td><code>BaseService</code></td>
        <td><p>The service to start.</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>timeout</code></td>
        <td><code>int</code></td>
        <td><p>Timeout in seconds to wait for the service to start.</p></td>
        <td><code>60</code></td>
      </tr>
  </tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>BaseService</code></td>
      <td><p>The started service.</p></td>
    </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>zenml/integrations/vllm/model_deployers/vllm_model_deployer.py</code></summary>
          <div class="highlight"><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">perform_start_model</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">service</span><span class="p">:</span> <span class="n">BaseService</span><span class="p">,</span>
    <span class="n">timeout</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="n">DEFAULT_SERVICE_START_STOP_TIMEOUT</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">BaseService</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Method to start a model server.</span>

<span class="sd">    Args:</span>
<span class="sd">        service: The service to start.</span>
<span class="sd">        timeout: Timeout in seconds to wait for the service to start.</span>

<span class="sd">    Returns:</span>
<span class="sd">        The started service.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">service</span><span class="o">.</span><span class="n">start</span><span class="p">(</span><span class="n">timeout</span><span class="o">=</span><span class="n">timeout</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">service</span>
</code></pre></div>
        </details>
    </div>

  </div>



  <div class="doc doc-object doc-method">



<h6 id="zenml.integrations.vllm.model_deployers.vllm_model_deployer.VLLMModelDeployer.perform_stop_model" class="doc doc-heading">
<code class="highlight language-python"><span class="n">perform_stop_model</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">service</span><span class="p">,</span> <span class="n">timeout</span><span class="o">=</span><span class="mi">60</span><span class="p">,</span> <span class="n">force</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span></code>


</h6>

    <div class="doc doc-contents ">

      <p>Method to stop a model server.</p>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>service</code></td>
        <td><code>BaseService</code></td>
        <td><p>The service to stop.</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>timeout</code></td>
        <td><code>int</code></td>
        <td><p>Timeout in seconds to wait for the service to stop.</p></td>
        <td><code>60</code></td>
      </tr>
      <tr>
        <td><code>force</code></td>
        <td><code>bool</code></td>
        <td><p>If True, force the service to stop.</p></td>
        <td><code>False</code></td>
      </tr>
  </tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>BaseService</code></td>
      <td><p>The stopped service.</p></td>
    </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>zenml/integrations/vllm/model_deployers/vllm_model_deployer.py</code></summary>
          <div class="highlight"><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">perform_stop_model</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">service</span><span class="p">:</span> <span class="n">BaseService</span><span class="p">,</span>
    <span class="n">timeout</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="n">DEFAULT_SERVICE_START_STOP_TIMEOUT</span><span class="p">,</span>
    <span class="n">force</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">BaseService</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Method to stop a model server.</span>

<span class="sd">    Args:</span>
<span class="sd">        service: The service to stop.</span>
<span class="sd">        timeout: Timeout in seconds to wait for the service to stop.</span>
<span class="sd">        force: If True, force the service to stop.</span>

<span class="sd">    Returns:</span>
<span class="sd">        The stopped service.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">service</span><span class="o">.</span><span class="n">stop</span><span class="p">(</span><span class="n">timeout</span><span class="o">=</span><span class="n">timeout</span><span class="p">,</span> <span class="n">force</span><span class="o">=</span><span class="n">force</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">service</span>
</code></pre></div>
        </details>
    </div>

  </div>





  </div>

    </div>

  </div>







  </div>

    </div>

  </div>




  </div>

    </div>

  </div>



  <div class="doc doc-object doc-module">



<h3 id="zenml.integrations.vllm.services" class="doc doc-heading">
        <code>services</code>


  <span class="doc doc-properties">
      <small class="doc doc-property doc-property-special"><code>special</code></small>
  </span>

</h3>

    <div class="doc doc-contents ">

      <p>Initialization of the vLLM Inference Server.</p>



  <div class="doc doc-children">










  <div class="doc doc-object doc-module">



<h4 id="zenml.integrations.vllm.services.vllm_deployment" class="doc doc-heading">
        <code>vllm_deployment</code>



</h4>

    <div class="doc doc-contents ">

      <p>Implementation of the vLLM Inference Server Service.</p>



  <div class="doc doc-children">










  <div class="doc doc-object doc-class">



<h5 id="zenml.integrations.vllm.services.vllm_deployment.VLLMDeploymentEndpoint" class="doc doc-heading">
        <code>
VLLMDeploymentEndpoint            (<a class="autorefs autorefs-internal" title="zenml.services.local.local_service_endpoint.LocalDaemonServiceEndpoint" href="../../core_code_docs/core-services/#zenml.services.local.local_service_endpoint.LocalDaemonServiceEndpoint">LocalDaemonServiceEndpoint</a>)
        </code>



</h5>

    <div class="doc doc-contents ">

      <p>A service endpoint exposed by the vLLM deployment daemon.</p>

<p><strong>Attributes:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>config</code></td>
        <td><code>VLLMDeploymentEndpointConfig</code></td>
        <td><p>service endpoint configuration</p></td>
      </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>zenml/integrations/vllm/services/vllm_deployment.py</code></summary>
          <div class="highlight"><pre><span></span><code><span class="k">class</span><span class="w"> </span><span class="nc">VLLMDeploymentEndpoint</span><span class="p">(</span><span class="n">LocalDaemonServiceEndpoint</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;A service endpoint exposed by the vLLM deployment daemon.</span>

<span class="sd">    Attributes:</span>
<span class="sd">        config: service endpoint configuration</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">config</span><span class="p">:</span> <span class="n">VLLMDeploymentEndpointConfig</span>
    <span class="n">monitor</span><span class="p">:</span> <span class="n">HTTPEndpointHealthMonitor</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">prediction_url</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Gets the prediction URL for the endpoint.</span>

<span class="sd">        Returns:</span>
<span class="sd">            the prediction URL for the endpoint</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">uri</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">status</span><span class="o">.</span><span class="n">uri</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">uri</span><span class="p">:</span>
            <span class="k">return</span> <span class="kc">None</span>
        <span class="k">return</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">uri</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">prediction_url_path</span><span class="p">)</span>
</code></pre></div>
        </details>



  <div class="doc doc-children">





















  <div class="doc doc-object doc-attribute">



<h6 id="zenml.integrations.vllm.services.vllm_deployment.VLLMDeploymentEndpoint.prediction_url" class="doc doc-heading">
<code class="highlight language-python"><span class="n">prediction_url</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span></code>

  <span class="doc doc-properties">
      <small class="doc doc-property doc-property-property"><code>property</code></small>
      <small class="doc doc-property doc-property-readonly"><code>readonly</code></small>
  </span>

</h6>

    <div class="doc doc-contents ">

      <p>Gets the prediction URL for the endpoint.</p>

<p><strong>Returns:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>Optional[str]</code></td>
      <td><p>the prediction URL for the endpoint</p></td>
    </tr>
  </tbody>
</table>    </div>

  </div>








  </div>

    </div>

  </div>



  <div class="doc doc-object doc-class">



<h5 id="zenml.integrations.vllm.services.vllm_deployment.VLLMDeploymentEndpointConfig" class="doc doc-heading">
        <code>
VLLMDeploymentEndpointConfig            (<a class="autorefs autorefs-internal" title="zenml.services.local.local_service_endpoint.LocalDaemonServiceEndpointConfig" href="../../core_code_docs/core-services/#zenml.services.local.local_service_endpoint.LocalDaemonServiceEndpointConfig">LocalDaemonServiceEndpointConfig</a>)
        </code>



</h5>

    <div class="doc doc-contents ">

      <p>vLLM deployment service configuration.</p>

<p><strong>Attributes:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>prediction_url_path</code></td>
        <td><code>str</code></td>
        <td><p>URI subpath for prediction requests</p></td>
      </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>zenml/integrations/vllm/services/vllm_deployment.py</code></summary>
          <div class="highlight"><pre><span></span><code><span class="k">class</span><span class="w"> </span><span class="nc">VLLMDeploymentEndpointConfig</span><span class="p">(</span><span class="n">LocalDaemonServiceEndpointConfig</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;vLLM deployment service configuration.</span>

<span class="sd">    Attributes:</span>
<span class="sd">        prediction_url_path: URI subpath for prediction requests</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">prediction_url_path</span><span class="p">:</span> <span class="nb">str</span>
</code></pre></div>
        </details>



  <div class="doc doc-children">


























  </div>

    </div>

  </div>



  <div class="doc doc-object doc-class">



<h5 id="zenml.integrations.vllm.services.vllm_deployment.VLLMDeploymentService" class="doc doc-heading">
        <code>
VLLMDeploymentService            (<a class="autorefs autorefs-internal" title="zenml.services.local.local_service.LocalDaemonService" href="../../core_code_docs/core-services/#zenml.services.local.local_service.LocalDaemonService">LocalDaemonService</a>, <a class="autorefs autorefs-internal" title="zenml.services.service.BaseDeploymentService" href="../../core_code_docs/core-services/#zenml.services.service.BaseDeploymentService">BaseDeploymentService</a>)
        </code>



</h5>

    <div class="doc doc-contents ">

      <p>vLLM Inference Server Deployment Service.</p>

        <details class="quote">
          <summary>Source code in <code>zenml/integrations/vllm/services/vllm_deployment.py</code></summary>
          <div class="highlight"><pre><span></span><code><span class="k">class</span><span class="w"> </span><span class="nc">VLLMDeploymentService</span><span class="p">(</span><span class="n">LocalDaemonService</span><span class="p">,</span> <span class="n">BaseDeploymentService</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;vLLM Inference Server Deployment Service.&quot;&quot;&quot;</span>

    <span class="n">SERVICE_TYPE</span> <span class="o">=</span> <span class="n">ServiceType</span><span class="p">(</span>
        <span class="n">name</span><span class="o">=</span><span class="s2">&quot;vllm-deployment&quot;</span><span class="p">,</span>
        <span class="nb">type</span><span class="o">=</span><span class="s2">&quot;model-serving&quot;</span><span class="p">,</span>
        <span class="n">flavor</span><span class="o">=</span><span class="s2">&quot;vllm&quot;</span><span class="p">,</span>
        <span class="n">description</span><span class="o">=</span><span class="s2">&quot;vLLM Inference prediction service&quot;</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">config</span><span class="p">:</span> <span class="n">VLLMServiceConfig</span>
    <span class="n">endpoint</span><span class="p">:</span> <span class="n">VLLMDeploymentEndpoint</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">config</span><span class="p">:</span> <span class="n">VLLMServiceConfig</span><span class="p">,</span> <span class="o">**</span><span class="n">attrs</span><span class="p">:</span> <span class="n">Any</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Initialize the vLLM deployment service.</span>

<span class="sd">        Args:</span>
<span class="sd">            config: service configuration</span>
<span class="sd">            attrs: additional attributes to set on the service</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">config</span><span class="p">,</span> <span class="n">VLLMServiceConfig</span><span class="p">)</span> <span class="ow">and</span> <span class="s2">&quot;endpoint&quot;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">attrs</span><span class="p">:</span>
            <span class="n">endpoint</span> <span class="o">=</span> <span class="n">VLLMDeploymentEndpoint</span><span class="p">(</span>
                <span class="n">config</span><span class="o">=</span><span class="n">VLLMDeploymentEndpointConfig</span><span class="p">(</span>
                    <span class="n">protocol</span><span class="o">=</span><span class="n">ServiceEndpointProtocol</span><span class="o">.</span><span class="n">HTTP</span><span class="p">,</span>
                    <span class="n">port</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">port</span><span class="p">,</span>
                    <span class="n">ip_address</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">host</span> <span class="ow">or</span> <span class="n">DEFAULT_LOCAL_SERVICE_IP_ADDRESS</span><span class="p">,</span>
                    <span class="n">prediction_url_path</span><span class="o">=</span><span class="n">VLLM_PREDICTION_URL_PATH</span><span class="p">,</span>
                <span class="p">),</span>
                <span class="n">monitor</span><span class="o">=</span><span class="n">HTTPEndpointHealthMonitor</span><span class="p">(</span>
                    <span class="n">config</span><span class="o">=</span><span class="n">HTTPEndpointHealthMonitorConfig</span><span class="p">(</span>
                        <span class="n">healthcheck_uri_path</span><span class="o">=</span><span class="n">VLLM_HEALTHCHECK_URL_PATH</span><span class="p">,</span>
                    <span class="p">)</span>
                <span class="p">),</span>
            <span class="p">)</span>
            <span class="n">attrs</span><span class="p">[</span><span class="s2">&quot;endpoint&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">endpoint</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">config</span><span class="o">=</span><span class="n">config</span><span class="p">,</span> <span class="o">**</span><span class="n">attrs</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">run</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Start the service.&quot;&quot;&quot;</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
            <span class="s2">&quot;Starting vLLM inference server service as blocking &quot;</span>
            <span class="s2">&quot;process... press CTRL+C once to stop it.&quot;</span>
        <span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">endpoint</span><span class="o">.</span><span class="n">prepare_for_start</span><span class="p">()</span>

        <span class="kn">import</span><span class="w"> </span><span class="nn">uvloop</span>
        <span class="kn">from</span><span class="w"> </span><span class="nn">vllm.entrypoints.openai.api_server</span><span class="w"> </span><span class="kn">import</span> <span class="p">(</span>
            <span class="n">run_server</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="kn">from</span><span class="w"> </span><span class="nn">vllm.entrypoints.openai.cli_args</span><span class="w"> </span><span class="kn">import</span> <span class="p">(</span>
            <span class="n">make_arg_parser</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="kn">from</span><span class="w"> </span><span class="nn">vllm.utils</span><span class="w"> </span><span class="kn">import</span> <span class="p">(</span>
            <span class="n">FlexibleArgumentParser</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="k">try</span><span class="p">:</span>
            <span class="n">parser</span><span class="p">:</span> <span class="n">argparse</span><span class="o">.</span><span class="n">ArgumentParser</span> <span class="o">=</span> <span class="n">make_arg_parser</span><span class="p">(</span>
                <span class="n">FlexibleArgumentParser</span><span class="p">()</span>
            <span class="p">)</span>
            <span class="c1"># pass in empty list to get default args</span>
            <span class="c1"># otherwise it will try to get the args from sys.argv</span>
            <span class="c1"># and if there&#39;s a --config in there, it will want to use</span>
            <span class="c1"># that file for vLLM configuration, which is not what we want</span>
            <span class="n">args</span><span class="p">:</span> <span class="n">argparse</span><span class="o">.</span><span class="n">Namespace</span> <span class="o">=</span> <span class="n">parser</span><span class="o">.</span><span class="n">parse_args</span><span class="p">(</span><span class="n">args</span><span class="o">=</span><span class="p">[])</span>
            <span class="c1"># Override port with the available port</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">port</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">endpoint</span><span class="o">.</span><span class="n">status</span><span class="o">.</span><span class="n">port</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">port</span>

            <span class="c1"># Update the arguments in place</span>
            <span class="n">args</span><span class="o">.</span><span class="vm">__dict__</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model_dump</span><span class="p">())</span>
            <span class="n">uvloop</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">run_server</span><span class="p">(</span><span class="n">args</span><span class="o">=</span><span class="n">args</span><span class="p">))</span>
        <span class="k">except</span> <span class="ne">KeyboardInterrupt</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Stopping vLLM prediction service...&quot;</span><span class="p">)</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">prediction_url</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Gets the prediction URL for the endpoint.</span>

<span class="sd">        Returns:</span>
<span class="sd">            the prediction URL for the endpoint</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">is_running</span><span class="p">:</span>
            <span class="k">return</span> <span class="kc">None</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">endpoint</span><span class="o">.</span><span class="n">prediction_url</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">:</span> <span class="s2">&quot;Any&quot;</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="s2">&quot;Any&quot;</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Make a prediction using the service.</span>

<span class="sd">        Args:</span>
<span class="sd">            data: data to make a prediction on</span>

<span class="sd">        Returns:</span>
<span class="sd">            The prediction result.</span>

<span class="sd">        Raises:</span>
<span class="sd">            Exception: if the service is not running</span>
<span class="sd">            ValueError: if the prediction endpoint is unknown.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">is_running</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span>
                <span class="s2">&quot;vLLM Inference service is not running. &quot;</span>
                <span class="s2">&quot;Please start the service before making predictions.&quot;</span>
            <span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">endpoint</span><span class="o">.</span><span class="n">prediction_url</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="kn">from</span><span class="w"> </span><span class="nn">openai</span><span class="w"> </span><span class="kn">import</span> <span class="n">OpenAI</span>

            <span class="n">client</span> <span class="o">=</span> <span class="n">OpenAI</span><span class="p">(</span>
                <span class="n">api_key</span><span class="o">=</span><span class="s2">&quot;EMPTY&quot;</span><span class="p">,</span>
                <span class="n">base_url</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">endpoint</span><span class="o">.</span><span class="n">prediction_url</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="n">models</span> <span class="o">=</span> <span class="n">client</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">list</span><span class="p">()</span>
            <span class="n">model</span> <span class="o">=</span> <span class="n">models</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">id</span>
            <span class="n">result</span> <span class="o">=</span> <span class="n">client</span><span class="o">.</span><span class="n">completions</span><span class="o">.</span><span class="n">create</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span> <span class="n">prompt</span><span class="o">=</span><span class="n">data</span><span class="p">)</span>
            <span class="c1"># TODO: We can add support for client.chat.completions.create</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;No endpoint known for prediction.&quot;</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">result</span>
</code></pre></div>
        </details>



  <div class="doc doc-children">






















  <div class="doc doc-object doc-attribute">



<h6 id="zenml.integrations.vllm.services.vllm_deployment.VLLMDeploymentService.prediction_url" class="doc doc-heading">
<code class="highlight language-python"><span class="n">prediction_url</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span></code>

  <span class="doc doc-properties">
      <small class="doc doc-property doc-property-property"><code>property</code></small>
      <small class="doc doc-property doc-property-readonly"><code>readonly</code></small>
  </span>

</h6>

    <div class="doc doc-contents ">

      <p>Gets the prediction URL for the endpoint.</p>

<p><strong>Returns:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>Optional[str]</code></td>
      <td><p>the prediction URL for the endpoint</p></td>
    </tr>
  </tbody>
</table>    </div>

  </div>






  <div class="doc doc-object doc-method">



<h6 id="zenml.integrations.vllm.services.vllm_deployment.VLLMDeploymentService.__init__" class="doc doc-heading">
<code class="highlight language-python"><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">config</span><span class="p">,</span> <span class="o">**</span><span class="n">attrs</span><span class="p">)</span></code>

  <span class="doc doc-properties">
      <small class="doc doc-property doc-property-special"><code>special</code></small>
  </span>

</h6>

    <div class="doc doc-contents ">

      <p>Initialize the vLLM deployment service.</p>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>config</code></td>
        <td><code>VLLMServiceConfig</code></td>
        <td><p>service configuration</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>attrs</code></td>
        <td><code>Any</code></td>
        <td><p>additional attributes to set on the service</p></td>
        <td><code>{}</code></td>
      </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>zenml/integrations/vllm/services/vllm_deployment.py</code></summary>
          <div class="highlight"><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">config</span><span class="p">:</span> <span class="n">VLLMServiceConfig</span><span class="p">,</span> <span class="o">**</span><span class="n">attrs</span><span class="p">:</span> <span class="n">Any</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Initialize the vLLM deployment service.</span>

<span class="sd">    Args:</span>
<span class="sd">        config: service configuration</span>
<span class="sd">        attrs: additional attributes to set on the service</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">config</span><span class="p">,</span> <span class="n">VLLMServiceConfig</span><span class="p">)</span> <span class="ow">and</span> <span class="s2">&quot;endpoint&quot;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">attrs</span><span class="p">:</span>
        <span class="n">endpoint</span> <span class="o">=</span> <span class="n">VLLMDeploymentEndpoint</span><span class="p">(</span>
            <span class="n">config</span><span class="o">=</span><span class="n">VLLMDeploymentEndpointConfig</span><span class="p">(</span>
                <span class="n">protocol</span><span class="o">=</span><span class="n">ServiceEndpointProtocol</span><span class="o">.</span><span class="n">HTTP</span><span class="p">,</span>
                <span class="n">port</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">port</span><span class="p">,</span>
                <span class="n">ip_address</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">host</span> <span class="ow">or</span> <span class="n">DEFAULT_LOCAL_SERVICE_IP_ADDRESS</span><span class="p">,</span>
                <span class="n">prediction_url_path</span><span class="o">=</span><span class="n">VLLM_PREDICTION_URL_PATH</span><span class="p">,</span>
            <span class="p">),</span>
            <span class="n">monitor</span><span class="o">=</span><span class="n">HTTPEndpointHealthMonitor</span><span class="p">(</span>
                <span class="n">config</span><span class="o">=</span><span class="n">HTTPEndpointHealthMonitorConfig</span><span class="p">(</span>
                    <span class="n">healthcheck_uri_path</span><span class="o">=</span><span class="n">VLLM_HEALTHCHECK_URL_PATH</span><span class="p">,</span>
                <span class="p">)</span>
            <span class="p">),</span>
        <span class="p">)</span>
        <span class="n">attrs</span><span class="p">[</span><span class="s2">&quot;endpoint&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">endpoint</span>
    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">config</span><span class="o">=</span><span class="n">config</span><span class="p">,</span> <span class="o">**</span><span class="n">attrs</span><span class="p">)</span>
</code></pre></div>
        </details>
    </div>

  </div>



  <div class="doc doc-object doc-method">



<h6 id="zenml.integrations.vllm.services.vllm_deployment.VLLMDeploymentService.predict" class="doc doc-heading">
<code class="highlight language-python"><span class="n">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">)</span></code>


</h6>

    <div class="doc doc-contents ">

      <p>Make a prediction using the service.</p>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>data</code></td>
        <td><code>Any</code></td>
        <td><p>data to make a prediction on</p></td>
        <td><em>required</em></td>
      </tr>
  </tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>Any</code></td>
      <td><p>The prediction result.</p></td>
    </tr>
  </tbody>
</table>
<p><strong>Exceptions:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>Exception</code></td>
        <td><p>if the service is not running</p></td>
      </tr>
      <tr>
        <td><code>ValueError</code></td>
        <td><p>if the prediction endpoint is unknown.</p></td>
      </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>zenml/integrations/vllm/services/vllm_deployment.py</code></summary>
          <div class="highlight"><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">:</span> <span class="s2">&quot;Any&quot;</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="s2">&quot;Any&quot;</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Make a prediction using the service.</span>

<span class="sd">    Args:</span>
<span class="sd">        data: data to make a prediction on</span>

<span class="sd">    Returns:</span>
<span class="sd">        The prediction result.</span>

<span class="sd">    Raises:</span>
<span class="sd">        Exception: if the service is not running</span>
<span class="sd">        ValueError: if the prediction endpoint is unknown.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">is_running</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span>
            <span class="s2">&quot;vLLM Inference service is not running. &quot;</span>
            <span class="s2">&quot;Please start the service before making predictions.&quot;</span>
        <span class="p">)</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">endpoint</span><span class="o">.</span><span class="n">prediction_url</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="kn">from</span><span class="w"> </span><span class="nn">openai</span><span class="w"> </span><span class="kn">import</span> <span class="n">OpenAI</span>

        <span class="n">client</span> <span class="o">=</span> <span class="n">OpenAI</span><span class="p">(</span>
            <span class="n">api_key</span><span class="o">=</span><span class="s2">&quot;EMPTY&quot;</span><span class="p">,</span>
            <span class="n">base_url</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">endpoint</span><span class="o">.</span><span class="n">prediction_url</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">models</span> <span class="o">=</span> <span class="n">client</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">list</span><span class="p">()</span>
        <span class="n">model</span> <span class="o">=</span> <span class="n">models</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">id</span>
        <span class="n">result</span> <span class="o">=</span> <span class="n">client</span><span class="o">.</span><span class="n">completions</span><span class="o">.</span><span class="n">create</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span> <span class="n">prompt</span><span class="o">=</span><span class="n">data</span><span class="p">)</span>
        <span class="c1"># TODO: We can add support for client.chat.completions.create</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;No endpoint known for prediction.&quot;</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">result</span>
</code></pre></div>
        </details>
    </div>

  </div>



  <div class="doc doc-object doc-method">



<h6 id="zenml.integrations.vllm.services.vllm_deployment.VLLMDeploymentService.run" class="doc doc-heading">
<code class="highlight language-python"><span class="n">run</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span></code>


</h6>

    <div class="doc doc-contents ">

      <p>Start the service.</p>

        <details class="quote">
          <summary>Source code in <code>zenml/integrations/vllm/services/vllm_deployment.py</code></summary>
          <div class="highlight"><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">run</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Start the service.&quot;&quot;&quot;</span>
    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
        <span class="s2">&quot;Starting vLLM inference server service as blocking &quot;</span>
        <span class="s2">&quot;process... press CTRL+C once to stop it.&quot;</span>
    <span class="p">)</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">endpoint</span><span class="o">.</span><span class="n">prepare_for_start</span><span class="p">()</span>

    <span class="kn">import</span><span class="w"> </span><span class="nn">uvloop</span>
    <span class="kn">from</span><span class="w"> </span><span class="nn">vllm.entrypoints.openai.api_server</span><span class="w"> </span><span class="kn">import</span> <span class="p">(</span>
        <span class="n">run_server</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="kn">from</span><span class="w"> </span><span class="nn">vllm.entrypoints.openai.cli_args</span><span class="w"> </span><span class="kn">import</span> <span class="p">(</span>
        <span class="n">make_arg_parser</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="kn">from</span><span class="w"> </span><span class="nn">vllm.utils</span><span class="w"> </span><span class="kn">import</span> <span class="p">(</span>
        <span class="n">FlexibleArgumentParser</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="k">try</span><span class="p">:</span>
        <span class="n">parser</span><span class="p">:</span> <span class="n">argparse</span><span class="o">.</span><span class="n">ArgumentParser</span> <span class="o">=</span> <span class="n">make_arg_parser</span><span class="p">(</span>
            <span class="n">FlexibleArgumentParser</span><span class="p">()</span>
        <span class="p">)</span>
        <span class="c1"># pass in empty list to get default args</span>
        <span class="c1"># otherwise it will try to get the args from sys.argv</span>
        <span class="c1"># and if there&#39;s a --config in there, it will want to use</span>
        <span class="c1"># that file for vLLM configuration, which is not what we want</span>
        <span class="n">args</span><span class="p">:</span> <span class="n">argparse</span><span class="o">.</span><span class="n">Namespace</span> <span class="o">=</span> <span class="n">parser</span><span class="o">.</span><span class="n">parse_args</span><span class="p">(</span><span class="n">args</span><span class="o">=</span><span class="p">[])</span>
        <span class="c1"># Override port with the available port</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">port</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">endpoint</span><span class="o">.</span><span class="n">status</span><span class="o">.</span><span class="n">port</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">port</span>

        <span class="c1"># Update the arguments in place</span>
        <span class="n">args</span><span class="o">.</span><span class="vm">__dict__</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model_dump</span><span class="p">())</span>
        <span class="n">uvloop</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">run_server</span><span class="p">(</span><span class="n">args</span><span class="o">=</span><span class="n">args</span><span class="p">))</span>
    <span class="k">except</span> <span class="ne">KeyboardInterrupt</span><span class="p">:</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Stopping vLLM prediction service...&quot;</span><span class="p">)</span>
</code></pre></div>
        </details>
    </div>

  </div>





  </div>

    </div>

  </div>



  <div class="doc doc-object doc-class">



<h5 id="zenml.integrations.vllm.services.vllm_deployment.VLLMServiceConfig" class="doc doc-heading">
        <code>
VLLMServiceConfig            (<a class="autorefs autorefs-internal" title="zenml.services.local.local_service.LocalDaemonServiceConfig" href="../../core_code_docs/core-services/#zenml.services.local.local_service.LocalDaemonServiceConfig">LocalDaemonServiceConfig</a>)
        </code>



</h5>

    <div class="doc doc-contents ">

      <p>vLLM service configurations.</p>

        <details class="quote">
          <summary>Source code in <code>zenml/integrations/vllm/services/vllm_deployment.py</code></summary>
          <div class="highlight"><pre><span></span><code><span class="k">class</span><span class="w"> </span><span class="nc">VLLMServiceConfig</span><span class="p">(</span><span class="n">LocalDaemonServiceConfig</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;vLLM service configurations.&quot;&quot;&quot;</span>

    <span class="n">model</span><span class="p">:</span> <span class="nb">str</span>
    <span class="n">port</span><span class="p">:</span> <span class="nb">int</span>
    <span class="n">host</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="n">blocking</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span>
    <span class="c1"># If unspecified, model name or path will be used.</span>
    <span class="n">tokenizer</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="n">served_model_name</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]]]</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="c1"># Trust remote code from huggingface.</span>
    <span class="n">trust_remote_code</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="c1"># [&#39;auto&#39;, &#39;slow&#39;, &#39;mistral&#39;]</span>
    <span class="n">tokenizer_mode</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;auto&quot;</span>
    <span class="c1"># [&#39;auto&#39;, &#39;half&#39;, &#39;float16&#39;, &#39;bfloat16&#39;, &#39;float&#39;, &#39;float32&#39;]</span>
    <span class="n">dtype</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;auto&quot;</span>
    <span class="c1"># The specific model version to use. It can be a branch name, a tag name, or a commit id.</span>
    <span class="c1"># If unspecified, will use the default version.</span>
    <span class="n">revision</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
</code></pre></div>
        </details>



  <div class="doc doc-children">


























  </div>

    </div>

  </div>







  </div>

    </div>

  </div>




  </div>

    </div>

  </div>




  </div>

    </div>

  </div>





                
              </article>
            </div>
          
          
        </div>
        
      </main>
      
        <footer class="md-footer">
  
    
    <nav class="md-footer__inner md-grid" aria-label="Footer" >
      
        
        <a href="../integrations-utils/" class="md-footer__link md-footer__link--prev" aria-label="Previous: Utils" rel="prev">
          <div class="md-footer__button md-icon">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg>
          </div>
          <div class="md-footer__title">
            <div class="md-ellipsis">
              <span class="md-footer__direction">
                Previous
              </span>
              Utils
            </div>
          </div>
        </a>
      
      
        
        <a href="../integrations-wandb/" class="md-footer__link md-footer__link--next" aria-label="Next: Wandb" rel="next">
          <div class="md-footer__title">
            <div class="md-ellipsis">
              <span class="md-footer__direction">
                Next
              </span>
              Wandb
            </div>
          </div>
          <div class="md-footer__button md-icon">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11H4Z"/></svg>
          </div>
        </a>
      
    </nav>
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
    <div class="md-copyright__highlight">
      Copyright &copy; 2022 ZenML GmbH – <a href="#__consent">Change cookie settings</a>

    </div>
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
      <div class="md-consent" data-md-component="consent" id="__consent" hidden>
        <div class="md-consent__overlay"></div>
        <aside class="md-consent__inner">
          <form class="md-consent__form md-grid md-typeset" name="consent">
            


  
    
  




<h4>This website uses cookies</h4>
<p>We use cookies to recognize your repeated visits and preferences, as well as to measure the effectiveness of our documentation and whether users find what they're searching for. With your consent, you're helping us to make our documentation better.</p>
<input class="md-toggle" type="checkbox" id="__settings" >
<div class="md-consent__settings">
  <ul class="task-list">
    
      
      
        
        
      
      <li class="task-list-item">
        <label class="task-list-control">
          <input type="checkbox" name="github" checked>
          <span class="task-list-indicator"></span>
          GitHub
        <label>
      </li>
    
  </ul>
</div>
<div class="md-consent__controls">
  
    
      <button class="md-button md-button--primary">Accept</button>
    
    
    
  
    
    
      <button type="reset" class="md-button md-button--primary">Reject</button>
    
    
  
    
    
    
      <label class="md-button" for="__settings">Manage settings</label>
    
  
</div>
          </form>
        </aside>
      </div>
      <script>var consent=__md_get("__consent");if(consent)for(var input of document.forms.consent.elements)input.name&&(input.checked=consent[input.name]||!1);else"file:"!==location.protocol&&setTimeout(function(){document.querySelector("[data-md-component=consent]").hidden=!1},250);var action,form=document.forms.consent;for(action of["submit","reset"])form.addEventListener(action,function(e){if(e.preventDefault(),"reset"===e.type)for(var n of document.forms.consent.elements)n.name&&(n.checked=!1);__md_set("__consent",Object.fromEntries(Array.from(new FormData(form).keys()).map(function(e){return[e,!0]}))),location.hash="",location.reload()})</script>
    
    <script id="__config" type="application/json">{"base": "../..", "features": [], "search": "../../assets/javascripts/workers/search.16e2a7d4.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.config.lang": "en", "search.config.pipeline": "trimmer, stopWordFilter", "search.config.separator": "[\\s\\-]+", "search.placeholder": "Search", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version.title": "Select version"}, "version": {"provider": "mike"}}</script>
    
    
      <script src="../../assets/javascripts/bundle.5a2dcb6a.min.js"></script>
      
    
    
  </body>
</html>